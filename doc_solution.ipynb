{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import re\n",
    "import Levenshtein\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "from jiwer import wer, cer\n",
    "from typing import Set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Levenshtein\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carregando os Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = yaml.safe_load(open(\"confs.yaml\"))\n",
    "predictors = confs[\"predictors\"] ### Importante! O cientista poderá usar apenas estas features para criar/aperfeiçoar o modelo\n",
    "text_target = confs[\"text_target\"]\n",
    "cols_to_keep = predictors + text_target + ['cnpj']\n",
    "df = pd.read_parquet(\"dados/train.parquet\")[cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparando os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Presenca de Valores `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValores NaN por coluna:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nTotal de linhas com algum valor NaN: {df.isnull().any(axis=1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nenhuma das colunas do conjunto de dados fornecido possui algum valor `NaN`, nao será necessária a realizacao de nenhum tratamento desse tipo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Presenca de Linhas Duplicadas\n",
    "\n",
    "Linhas duplicadas em relacao a todas as colunas do conjunto de dados serao removidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Número de linhas duplicadas: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "print(f\"Tamanho do conjunto original: {df.shape}\")\n",
    "print(f\"Tamanho do conjunto após remocao de linhas duplicadas em relacao a todas as colunas: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Remocao de Termos Irrelevantes\n",
    "\n",
    "Colunas com o sufixo `_cleaned` serao criadas para as colunas `user_input`, `razaosocial` e `nome_fantasia`. Nelas, termos como \"S.A.\", \"LTDA\", \"LTDA.\", \"S/A\", \"S.A\", \"Ltda\", \"Ltda.\", \"S/A.\", \"S.A.\", \"S.A\", \"Ltda\" e \"Ltda\" serao removidos baseados na seguinte suposicao:\n",
    "\n",
    " > **Usuários nao tem o hábito de utilizar esses termos ao se referir a nomes de empresas, então elas não devem ser consideradas na busca/retrieval**\n",
    "\n",
    "\n",
    "Essa remocao é importante, pois ao se calcular a similaridade entre um `user_input` e/ou `razaosocial` e `nome_fantasia`, as métricas de similaridade seriam prejudicadas na ausencia de tais termos no `user_input`. \n",
    "\n",
    "Também serao removidas acentos e stopwords da língua portuguesa, sobretudo preposicoes. Tais termos, por nao informarem sobre empresas específicas, podem prejudicar a acurácia das buscas/retrieval.\n",
    "Além disso, passaremos tudo para letras minúsculas, para evitar problemas de case-sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_text_cleaning(text, \n",
    "                               remove_accents=True,\n",
    "                               remove_stop_words=True, \n",
    "                               remove_company_suffixes=True,\n",
    "                               custom_stop_words=None,\n",
    "                               to_lowercase=True):\n",
    "    \"\"\"\n",
    "    Comprehensive text cleaning function\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): Input text\n",
    "    remove_accents (bool): Remove accents and normalize characters\n",
    "    remove_stop_words (bool): Remove Portuguese stop words\n",
    "    remove_company_suffixes (bool): Remove common company suffixes\n",
    "    custom_stop_words (set): Additional stop words to remove\n",
    "    to_lowercase (bool): Convert to lowercase\n",
    "    \n",
    "    Returns:\n",
    "    str: Cleaned text\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    if remove_accents:\n",
    "        text = unicodedata.normalize('NFD', text)\n",
    "        text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')\n",
    "        text = text.replace('ç', 'c').replace('Ç', 'C')\n",
    "    \n",
    "    if to_lowercase:\n",
    "        text = text.lower()\n",
    "    \n",
    "    if remove_company_suffixes:\n",
    "        patterns_to_remove = [\n",
    "        r'\\bS\\.?A\\.?\\b',           # S.A, SA, S.A., SA.\n",
    "        r'\\bS/A\\.?\\b',             # S/A, S/A.\n",
    "        r'\\bLTDA\\.?\\b',            # LTDA, LTDA.\n",
    "        r'\\bLIMITADA\\b',           # LIMITADA\n",
    "        r'\\bCIA\\.?\\b',             # CIA, CIA.\n",
    "        r'\\bCOMPANHIA\\b',          # COMPANHIA\n",
    "        r'\\bEMPRESA\\b',            # EMPRESA\n",
    "        r'\\bCOMERCIO\\b',           # COMERCIO\n",
    "        r'\\bSERVICOS?\\b',          # SERVICO, SERVICOS\n",
    "        r'\\bME\\b',                 # ME (Microempresa)\n",
    "        r'\\bEPP\\b',                # EPP (Empresa de Pequeno Porte)\n",
    "        r'\\bEIRELI\\b',             # EIRELI\n",
    "        r'\\bSOCIEDADE\\b',          # SOCIEDADE\n",
    "        r'ADMINISTRADORA\\b',       # ADMINISTRADORA\n",
    "        r'GERAL\\b',                # GERAL\n",
    "    ]\n",
    "        \n",
    "        for pattern in patterns_to_remove:\n",
    "            text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    if remove_stop_words:\n",
    "        portuguese_stop_words = {\n",
    "            'a', 'ao', 'aos', 'as', 'da', 'das', 'de', 'do', 'dos', 'e', 'em', 'na', \n",
    "            'nas', 'no', 'nos', 'o', 'os', 'para', 'por', 'com', 'um', 'uma', 'uns', \n",
    "            'umas', 'se', 'que', 'ou', 'mas', 'como', 'mais', 'muito', 'sua', 'seu',\n",
    "            'seus', 'suas', 'este', 'esta', 'estes', 'estas', 'esse', 'essa', 'esses',\n",
    "            'essas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'isso', 'aquilo'\n",
    "        }\n",
    "        \n",
    "        if custom_stop_words:\n",
    "            portuguese_stop_words.update(custom_stop_words)\n",
    "        \n",
    "        words = text.split()\n",
    "        words = [word for word in words if word.lower() not in portuguese_stop_words]\n",
    "        text = ' '.join(words)\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)      # Multiple spaces to single space\n",
    "    text = text.strip()                   # Remove leading/trailing spaces\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['user_input_cleaned'] = df['user_input'].apply(comprehensive_text_cleaning)\n",
    "df_cleaned['razaosocial_cleaned'] = df['razaosocial'].apply(comprehensive_text_cleaning)\n",
    "df_cleaned['nome_fantasia_cleaned'] = df['nome_fantasia'].apply(comprehensive_text_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Retriever com Métodos Clássicos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Definicao das Métricas\n",
    "\n",
    "As seguintes métricas de similaridade e erro entre strings a nível de caracter serao implementadas:\n",
    "\n",
    "***\n",
    "> ## Word Error Rate (WER): \n",
    "\n",
    " Calcula a taxa de erro a nível de palavras: \n",
    "  $$WER = \\frac{S + D + I}{N}$$\n",
    "  onde:\n",
    "  - $S$ é o número de substituições. Por exemplo, se o usuário digitou \"Empresa X\" e a referência é \"Empresa Y\", então há uma substituição.\n",
    "  - $D$ é o número de deleções. Por exemplo, se o usuário digitou \"Empresa\" e a referência é \"Empresa X\", então há uma deleção.\n",
    "  - $I$ é o número de inserções. Por exemplo, se o usuário digitou \"Empresa X Y\" e a referência é \"Empresa X\", então há uma inserção.\n",
    "  - $N$ é o número total de palavras na referência. Por exemplo, se a referência é \"Empresa X\", então $N$ é 2.\n",
    "\n",
    "***\n",
    "> ## Character Error Rate (CER): \n",
    "\n",
    "Calcula a taxa de erro a nível de caracteres:\n",
    "  $$CER = \\frac{S + D + I}{N}$$\n",
    "  onde:\n",
    "  - $S$ é o número de substituições. Por exemplo, se o usuário digitou \"EmpresaXY\" e a referência é \"EmpresaXZ\", então há uma substituição.\n",
    "  - $D$ é o número de deleções. Por exemplo, se o usuário digitou \"Empresa\" e a referência é \"EmpresaX\", então há uma deleção.\n",
    "  - $I$ é o número de inserções. Por exemplo, se o usuário digitou \"Empresa XY\" e a referência é \"Empresa X\", então há uma inserção.\n",
    "  - $N$ é o número total de caracteres na referência. Por exemplo, se a referência é \"Empresa X\", então $N$ é 9 (contando espaços).\n",
    "\n",
    "***\n",
    "> ## Distância de Levenshtein Normalizada: \n",
    "\n",
    "Mede a diferença entre duas sequências de caracteres. É definida como o número mínimo de operações de edição (inserções, deleções ou substituições) necessárias para transformar uma palavra em outra. A normalização é feita dividindo a distância pelo comprimento da maior palavra entre as comparadas:\n",
    "  $$D(A, B) = \\frac{L(A, B)}{max(|A|, |B|)}$$\n",
    "  onde $L(A, B)$ é a distância de Levenshtein entre as sequências $A$ e $B$, e $|A|$ e $|B|$ são os comprimentos das sequências.\n",
    "\n",
    "  Por exemplo, se temos o texto \"empresa X\" e \"empresa Y\", a distância de Levenshtein seria 1 (substituindo \"X\" por \"Y\"). A normalização seria:\n",
    "  $$D(\\text{\"empresa X\"}, \\text{\"empresa Y\"}) = \\frac{1}{9}$$\n",
    "\n",
    "***\n",
    "> ## Similaridade de Jaccard: \n",
    "\n",
    "Mede a similaridade entre dois conjuntos. É definida como o tamanho da interseção dividido pelo tamanho da união dos conjuntos.\n",
    "  $$J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}$$\n",
    "\n",
    "  No caso de textos, podemos considerar conjuntos de palavras ou caracteres. Por exemplo, se temos dois textos \"empresa X\" e \"empresa Y\", podemos considerar os conjuntos de palavras {empresa, X} e {empresa, Y}. A similaridade de Jaccard seria calculada como:\n",
    "  $$J(\\{empresa, X\\}, \\{empresa, Y\\}) = \\frac{|\\{empresa\\}|}{|\\{empresa, X, Y\\}|} = \\frac{1}{3}$$\n",
    "\n",
    "***\n",
    "> ## Similaridade de Jaccard N Gram: \n",
    "\n",
    "É uma extensão da similaridade de Jaccard que considera n-gramas (sequências de n itens contíguos) em vez de palavras ou caracteres individuais. É útil para capturar similaridades em sequências mais longas, como frases ou sentenças. \n",
    "  A fórmula é semelhante à similaridade de Jaccard, mas aplicada a n-gramas:\n",
    "  $$J(A, B) = \\frac{|A_n \\cap B_n|}{|A_n \\cup B_n|}$$\n",
    "\n",
    "No caso de textos, se temos o texto \"empresa X\", seus dois-gramas seriam {\"em\", \"mp\", \"pr\", \"re\", \"sa\", \"a \", \" X\"}. Seus três-gramas seriam {\"emp\", \"mpr\", \"pre\", \"res\", \"esa\", \"sa \", \"a X\"} e assim por diante. A similaridade de Jaccard N Gram seria calculada considerando esses n-gramas.\n",
    "\n",
    "Ela é útil para capturar similaridades em casos de comparação de textos com erros de digitação, com pequenas inversoes/omissoes de caracteres, como ao comparar \"emprEsa X\" e \"emprsa X\", onde a ordem dos caracteres é preservada, mas algumas letras estão fora de lugar.\n",
    "\n",
    "***\n",
    "\n",
    "> ## TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "\n",
    "É uma técnica de pontuação que mede a importância relativa de palavras em documentos. No contexto de matching entre input do usuário e registros de nome_fantasia/razao_social, o TF-IDF ajuda a identificar quais termos são mais distintivos para cada empresa, priorizando palavras raras e específicas sobre termos genéricos comuns.\n",
    "\n",
    "A fórmula combina dois componentes:\n",
    "\n",
    "**TF (Term Frequency):**\n",
    "$$TF(t,d) = \\frac{\\text{número de ocorrências do termo t no nome de empresa d}}{\\text{número total de termos no nome de empresa d}}$$\n",
    "\n",
    "**IDF (Inverse Document Frequency):**\n",
    "$$IDF(t,D) = \\log\\left(\\frac{\\text{número total de nomes distintos de empresas no corpus}}{\\text{número de nomes de empresas que contêm o termo t}}\\right)$$\n",
    "\n",
    "**TF-IDF final:**\n",
    "$$TF\\text{-}IDF(t,d,D) = TF(t,d) \\times IDF(t,D)$$\n",
    "\n",
    "**Onde:**\n",
    "- **t** = termo/palavra específica (ex: \"Petrobras\", \"S.A.\", \"Banco\")\n",
    "- **d** = no caso do problema, a razao social de uma empresa concatenada com seu nome fantasia, separados por um espaco (ex: \"Apple Inc. Apple\")\n",
    "- **D** = corpus completo com os nomes de todas as empresas definidas como o **d** acima.\n",
    "\n",
    "**Vetor Final:**\n",
    "Para cada nome de empresa **d**, o vetor TF-IDF tem dimensão igual ao número $n$ de termos únicos que formam todos os nomes de empresas no corpus $D$, onde cada posição representa o score TF-IDF de um termo:\n",
    "$$\\vec{v_d} = [TF\\text{-}IDF(t_1,d,D), TF\\text{-}IDF(t_2,d,D), ..., TF\\text{-}IDF(t_n,d,D)]$$\n",
    "\n",
    "O resultado desse processo é um **índice de vetores** em que cada um representa uma empresa específica. \n",
    "\n",
    "Termos raros em relacao a todos os nomes de empresas disponíveis com excecao daquela empresa a qual o termo se refere terao IDF grandes. Por exemplo, suponha que **D** é formado por nomes de empresas como \"Petrobras S.A.\", \"Magazine Luiza S.A.\" e \"Banco do Brasil S.A.\". Nesse caso, a palavra \"S.A.\" aparece em muitas empresas, fazendo que seu IDF seja baixo nos vetores $\\vec{v_d}$ todos os nomes de empresas e, portanto, nao tendo relevancia para distinguir nomes de empresas distintas.\n",
    "\n",
    "\"Petrobras\" aparece no nome de uma única empresa, portanto terá IDF alto. Quando o usuário digita \"petrobras\", o seu vetor TF-IDF é calculado para todos os nomes de empresas $d$ e o nome de empresa $d$ correspondente retornado pelo retriever é o aquele cujo vetor $\\vec{v_d}$ é o mais similar ao vetor correspondente ao input do usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextMetrics:\n",
    "    \"\"\"\n",
    "    A class containing various text comparison metrics with input validation.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_cer(reference: str, hypothesis: str) -> float:\n",
    "        \"\"\"Calculate Character Error Rate.\"\"\"\n",
    "        if not reference or not hypothesis:\n",
    "            return 1.0  # Worst case: 100% error\n",
    "        return cer(reference, hypothesis)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_wer(reference: str, hypothesis: str) -> float:\n",
    "        \"\"\"Calculate Word Error Rate.\"\"\"\n",
    "        if not reference or not hypothesis:\n",
    "            return 1.0  # Worst case: 100% error\n",
    "        return wer(reference, hypothesis)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_normalized_levenshtein(reference: str, hypothesis: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate normalized Levenshtein distance (0-1).\n",
    "        Returns:\n",
    "            float: Normalized Levenshtein distance between 0 and 1\n",
    "        \"\"\"\n",
    "        if not reference or not hypothesis:\n",
    "            return 1.0  # Worst case: maximum distance\n",
    "        max_len = max(len(reference), len(hypothesis))\n",
    "        if max_len == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        distance = Levenshtein.distance(reference, hypothesis)\n",
    "        return distance / max_len\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_character_set(text: str) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Convert text to a set of characters.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text\n",
    "            \n",
    "        Returns:\n",
    "            Set[str]: Set of characters from the input text\n",
    "        \"\"\"\n",
    "        return set(text)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_word_set(text: str) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Convert text to a set of words.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text\n",
    "            \n",
    "        Returns:\n",
    "            Set[str]: Set of words from the input text\n",
    "        \"\"\"\n",
    "        return set(text.lower().split())\n",
    "\n",
    "    @staticmethod \n",
    "    def ngram_jaccard_similarity(reference: str, hypothesis: str, n=2):\n",
    "        \"\"\"\n",
    "        Calculate Jaccard similarity using character n-grams.\n",
    "        This handles inversions and some misspellings well.\n",
    "        \n",
    "        Args:\n",
    "            reference, hypothesis: Input strings\n",
    "            n: N-gram size (2=bigrams, 3=trigrams, etc.)\n",
    "        \"\"\"\n",
    "        if not reference or not hypothesis:\n",
    "            return 0.0  # Worst case: no similarity\n",
    "\n",
    "        def get_ngrams(text, n):\n",
    "            \"\"\"Generate n-grams from text with padding.\"\"\"\n",
    "            # Add padding to capture beginning/end patterns\n",
    "            padded = '#' * (n-1) + text.lower() + '#' * (n-1)\n",
    "            return set(padded[i:i+n] for i in range(len(padded) - n + 1))\n",
    "        \n",
    "        ngrams1 = get_ngrams(reference, n)\n",
    "        ngrams2 = get_ngrams(hypothesis, n)\n",
    "        \n",
    "        intersection = len(ngrams1 & ngrams2)\n",
    "        union = len(ngrams1 | ngrams2)\n",
    "        \n",
    "        return intersection / union if union > 0 else 1.0 if len(reference) == len(hypothesis) == 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Implementação do Retriever\n",
    "\n",
    "O retriever será implementado na classe `TextRetriever`.\n",
    "\n",
    "O método `TextRetrieval.find_best_matches` recebe um `user_input` e um dataframe contendo apenas as entradas correspondentes ao estado/`uf` daquele input e retorna os `k` `razaosocial` e `nome_fantasia` mais similares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Callable\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class SimilarityMetric(Enum):\n",
    "    CER = \"cer\"\n",
    "    WER = \"wer\"\n",
    "    LEVENSHTEIN = \"levenshtein\"\n",
    "    NGRAM_JACCARD = \"ngram_jaccard\"\n",
    "    TFIDF = \"tfidf\"\n",
    "\n",
    "\n",
    "class TextRetrieval:\n",
    "    \"\"\"\n",
    "    A class for text retrieval using similarity metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    _tfidf_cache = {}\n",
    "    \n",
    "    # The values of this dictionary are tuples in which the index 1 holds\n",
    "    # a boolean that tells whether a metric is such that the higher \n",
    "    # its value the more similar the strings being compared are\n",
    "    _METRIC_CONFIG = {\n",
    "        SimilarityMetric.CER: (TextMetrics.calculate_cer, False),\n",
    "        SimilarityMetric.WER: (TextMetrics.calculate_wer, False),\n",
    "        SimilarityMetric.LEVENSHTEIN: (TextMetrics.calculate_normalized_levenshtein, False),\n",
    "        SimilarityMetric.NGRAM_JACCARD: (TextMetrics.ngram_jaccard_similarity, True),\n",
    "        SimilarityMetric.TFIDF: (None, True),  \n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_tfidf_cache_key(df: pd.DataFrame) -> str:\n",
    "        return str(hash(pd.util.hash_pandas_object(df[[\"razaosocial_cleaned\", \"nome_fantasia_cleaned\"]], index=False).sum()))\n",
    "\n",
    "    @classmethod\n",
    "    def _get_tfidf_cache(cls, df: pd.DataFrame):\n",
    "        key = cls._get_tfidf_cache_key(df)\n",
    "        if key not in cls._tfidf_cache:\n",
    "            combined = (\n",
    "                df[\"razaosocial_cleaned\"].fillna('') + ' ' + df[\"nome_fantasia_cleaned\"].fillna('')\n",
    "            )\n",
    "            vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 4))\n",
    "            tfidf_matrix = vectorizer.fit_transform(combined)\n",
    "            cls._tfidf_cache[key] = (vectorizer, tfidf_matrix, combined)\n",
    "        return cls._tfidf_cache[key]\n",
    "\n",
    "    @staticmethod\n",
    "    def _retrieve_topk_cnpjs_from_pairs(\n",
    "        df: pd.DataFrame,\n",
    "        razao_social_list: List[str],\n",
    "        nome_fantasia_list: List[str],\n",
    "        cnpj_col: str = \"cnpj\",\n",
    "        not_cleaned_razao_col: str = \"razaosocial\",\n",
    "        not_cleaned_fantasia_col: str = \"nome_fantasia\",\n",
    "        top_k: int = 5\n",
    "    ) -> List[str]:\n",
    "        assert len(razao_social_list) == len(nome_fantasia_list)\n",
    "        mask = pd.Series(False, index=df.index)\n",
    "        for razao, fantasia in zip(razao_social_list, nome_fantasia_list):\n",
    "            mask |= ((df[not_cleaned_razao_col] == razao) & (df[not_cleaned_fantasia_col] == fantasia))\n",
    "        cnpjs = df[mask][cnpj_col].dropna().tolist()\n",
    "        most_common = Counter(cnpjs).most_common(top_k)\n",
    "        return [cnpj for cnpj, _ in most_common]\n",
    "\n",
    "    @classmethod\n",
    "    def find_best_matches(\n",
    "        cls,\n",
    "        user_input: str, \n",
    "        df: pd.DataFrame, \n",
    "        metric: SimilarityMetric, \n",
    "        top_k: int = 1\n",
    "    ) -> Tuple[List[str], List[str], List[float], List[float], List[str]]:\n",
    "\n",
    "        if metric == SimilarityMetric.TFIDF:\n",
    "            return cls._find_matches_tfidf(user_input, df, top_k)\n",
    "\n",
    "        if metric not in cls._METRIC_CONFIG:\n",
    "            raise ValueError(f\"Unsupported metric: {metric}\")\n",
    "        \n",
    "        metric_func, reverse_sort = cls._METRIC_CONFIG[metric]\n",
    "\n",
    "        return cls._find_matches_with_metric(\n",
    "            user_input, df, metric_func, reverse_sort, top_k\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _find_matches_tfidf(\n",
    "        cls,\n",
    "        user_input: str,\n",
    "        df: pd.DataFrame,\n",
    "        top_k: int,\n",
    "        not_cleaned_razao_col: str = \"razaosocial\",\n",
    "        not_cleaned_fantasia_col: str = \"nome_fantasia\",\n",
    "        cnpj_col: str = \"cnpj\"\n",
    "    ) -> Tuple[List[str], List[str], List[str]]:\n",
    "\n",
    "        vectorizer, tfidf_matrix, combined_col = cls._get_tfidf_cache(df)\n",
    "        query_vec = vectorizer.transform([user_input])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "        best_razao_matches = df.iloc[top_indices][not_cleaned_razao_col].tolist()\n",
    "        best_nome_fantasia_matches = df.iloc[top_indices][not_cleaned_fantasia_col].tolist()\n",
    "        best_cnpj_matches =  df.iloc[top_indices][cnpj_col].tolist()\n",
    "\n",
    "        return (\n",
    "            best_razao_matches,\n",
    "            best_nome_fantasia_matches,\n",
    "            best_cnpj_matches,\n",
    "            )\n",
    "\n",
    "    @classmethod\n",
    "    def _find_matches_with_metric(\n",
    "        cls,\n",
    "        user_input: str,\n",
    "        df: pd.DataFrame,\n",
    "        metric_func: Callable[[str, str], float],\n",
    "        reverse_sort: bool,\n",
    "        top_k: int,\n",
    "        razao_col: str = \"razaosocial_cleaned\",\n",
    "        fantasia_col: str = \"nome_fantasia_cleaned\",\n",
    "        not_cleaned_razao_col: str = \"razaosocial\",\n",
    "        not_cleaned_fantasia_col: str = \"nome_fantasia\",\n",
    "    ) -> Tuple[List[str], List[str], List[float], List[float], List[str]]:\n",
    "\n",
    "        valid_mask = ~(df[razao_col].isna() & df[fantasia_col].isna())\n",
    "        if not valid_mask.any():\n",
    "            return [], [], [], [], []\n",
    "\n",
    "        df_valid = df[valid_mask].copy()\n",
    "\n",
    "        razao_scores = df_valid[razao_col].apply(\n",
    "            lambda x: metric_func(x, user_input) if pd.notna(x) else None\n",
    "        )\n",
    "        nome_scores = df_valid[fantasia_col].apply(\n",
    "            lambda x: metric_func(x, user_input) if pd.notna(x) else None\n",
    "        )\n",
    "\n",
    "        if reverse_sort:\n",
    "            max_scores = np.maximum(\n",
    "                razao_scores.fillna(-np.inf), \n",
    "                nome_scores.fillna(-np.inf)\n",
    "            )\n",
    "        else:\n",
    "            max_scores = np.minimum(\n",
    "                razao_scores.fillna(np.inf), \n",
    "                nome_scores.fillna(np.inf)\n",
    "            )\n",
    "\n",
    "        sorted_indices = np.argsort(max_scores)\n",
    "        if reverse_sort:\n",
    "            sorted_indices = sorted_indices[::-1]\n",
    "\n",
    "        top_indices = sorted_indices[:top_k]\n",
    "        best_razao_matches = df_valid.iloc[top_indices][not_cleaned_razao_col].tolist()\n",
    "        best_nome_fantasia_matches = df_valid.iloc[top_indices][not_cleaned_fantasia_col].tolist()\n",
    "        best_cnpj_matches = cls._retrieve_topk_cnpjs_from_pairs(\n",
    "            df_valid,\n",
    "            best_razao_matches,\n",
    "            best_nome_fantasia_matches,\n",
    "            top_k=top_k\n",
    "        )\n",
    "\n",
    "        return best_razao_matches, best_nome_fantasia_matches, best_cnpj_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Escolha da Melhor Métrica\n",
    "\n",
    "\n",
    "Serao sorteadas `1000` linhas do conjunto de dados para calcular as métricas de similaridade e erro.\n",
    "\n",
    " Para cada linha, vamos calcular todas as métricas de similaridade mencionadas acima entre o `user_input_cleaned` e as colunas `razaosocial_cleaned` e `nome_fantasia_cleaned`. A métrica escolhida será aquela que apresentar o menor valor de erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_matching(df_sample: pd.DataFrame,\n",
    "                      df_cleaned: pd.DataFrame,\n",
    "                      metric: SimilarityMetric,\n",
    "                      top_k: int =5):\n",
    "    results = []\n",
    "\n",
    "    # Pre-group df_cleaned by UF for faster access\n",
    "    df_by_uf = {\n",
    "        uf: group.drop_duplicates(subset=['razaosocial_cleaned', 'nome_fantasia_cleaned','cnpj',])\n",
    "        for uf, group in df_cleaned.groupby('uf')\n",
    "    }\n",
    "\n",
    "    indexes = []\n",
    "    results_dict = {}\n",
    "    for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample), desc=\"Processing\"):\n",
    "        user_input = row['user_input_cleaned']\n",
    "        razaosocial = row['razaosocial_cleaned']\n",
    "        nome_fantasia = row['nome_fantasia_cleaned']\n",
    "        not_cleaned_user_input = row['user_input']\n",
    "        true_razaosocial = row['razaosocial']\n",
    "        true_nome_fantasia = row['nome_fantasia']\n",
    "        cnpj = row['cnpj']\n",
    "        uf = row['uf']\n",
    "\n",
    "        df_uf = df_by_uf.get(uf)\n",
    "        if df_uf is None or df_uf.empty:\n",
    "            continue  # Skip if no data for that UF\n",
    "\n",
    "        # One fast match call\n",
    "        top_k_razao, top_k_nome, top_k_cnpj = TextRetrieval.find_best_matches(\n",
    "            user_input, df_uf, metric, top_k=top_k\n",
    "        )\n",
    "\n",
    "        top_1_razao = top_k_razao[0] if top_k_razao else None\n",
    "        top_1_nome = top_k_nome[0] if top_k_nome else None\n",
    "        top_1_cnpj = top_k_cnpj[0] if top_k_cnpj else None\n",
    "\n",
    "        result_row = {\n",
    "            \"user_input\": user_input,\n",
    "            \"user_input_not_cleaned\": not_cleaned_user_input,\n",
    "            \"razaosocial_not_cleaned\": true_razaosocial,\n",
    "            \"nome_fantasia_not_cleaned\": true_nome_fantasia,\n",
    "            \"razaosocial\": razaosocial,\n",
    "            \"nome_fantasia\": nome_fantasia,\n",
    "            \"cnpj\": cnpj,\n",
    "            \"uf\": uf,\n",
    "            \n",
    "            \"top_1_razaosocial_retrieved\": top_1_razao,\n",
    "            \"top_1_nomefantasia_retrieved\": top_1_nome,\n",
    "            \"top_1_cnpj_retrieved\": top_1_cnpj,\n",
    "\n",
    "            \"top_1_razaosocial_pred\": top_1_razao == true_razaosocial if top_1_razao else False,\n",
    "            \"top_1_nomefantasia_pred\": top_1_nome == true_nome_fantasia if top_1_nome else False,\n",
    "            \"top_1_cnpj_pred\": top_1_cnpj == cnpj if top_1_cnpj else False,\n",
    "\n",
    "            \"top_5_razaosocial_pred\": true_razaosocial in top_k_razao,\n",
    "            \"top_5_nomefantasia_pred\": true_nome_fantasia in top_k_nome,\n",
    "            \"top_5_cnpj_pred\": cnpj in top_k_cnpj,\n",
    "\n",
    "\n",
    "        }\n",
    "\n",
    "        # Store results in a dictionary for easy access\n",
    "        results_dict[idx] = result_row\n",
    "        results_dict[idx]['top_k_razaosocial_pred'] = top_k_razao\n",
    "        results_dict[idx]['top_k_nomefantasia_pred'] = top_k_nome\n",
    "        results_dict[idx]['top_k_cnpj_pred'] = top_k_cnpj\n",
    "        \n",
    "\n",
    "        results.append(result_row)\n",
    "        indexes.append(idx)\n",
    "\n",
    "    results_df = pd.DataFrame(results, index=indexes)\n",
    "    return results_df, results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [SimilarityMetric.CER, \n",
    "           SimilarityMetric.WER,\n",
    "           SimilarityMetric.LEVENSHTEIN,\n",
    "           SimilarityMetric.NGRAM_JACCARD,\n",
    "           SimilarityMetric.TFIDF]\n",
    "\n",
    "sample_size = 1000\n",
    "top_k = 5\n",
    "df_sample = df_cleaned.sample(n=sample_size, random_state=42)\n",
    "accuracies = {metric.name: {} for metric in metrics}\n",
    "all_results_df = pd.DataFrame()\n",
    "for metric in metrics:\n",
    "    results_df, results_dict = evaluate_matching(df_sample, df_cleaned, metric, top_k=top_k)\n",
    "    results_df['metric'] = metric.name \n",
    "    all_results_df = pd.concat([all_results_df, results_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}\n",
    "for metric in metrics:\n",
    "    metric_name = metric.name\n",
    "    metric_df = all_results_df[all_results_df['metric'] == metric_name]\n",
    "    accuracies[metric_name] = {\n",
    "        'top_1_razaosocial': metric_df['top_1_razaosocial_pred'].mean(),\n",
    "        'top_1_nomefantasia': metric_df['top_1_nomefantasia_pred'].mean(),\n",
    "        'top_1_cnpj': metric_df['top_1_cnpj_pred'].mean(),\n",
    "        'top_5_razaosocial': metric_df['top_5_razaosocial_pred'].mean(),\n",
    "        'top_5_nomefantasia': metric_df['top_5_nomefantasia_pred'].mean(),\n",
    "        'top_5_cnpj': metric_df['top_5_cnpj_pred'].mean()\n",
    "    }\n",
    "\n",
    "cases = ['top_1_razaosocial', 'top_1_nomefantasia', 'top_1_cnpj', 'top_5_razaosocial', 'top_5_nomefantasia', 'top_5_cnpj']\n",
    "print(\"=\" * 100)\n",
    "for case in cases:\n",
    "    sorted_metrics = sorted(accuracies.items(), key=lambda x: x[1][case], reverse=True)\n",
    "    print(f\"Rankings for {case}:\")\n",
    "    for rank, (metric_name, _) in enumerate(sorted_metrics, start=1):\n",
    "        accuracy = accuracies[metric_name][case] * 100\n",
    "        print(f\"{rank}. {metric_name}: {accuracy:.2f}%\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observado acima, a métrica de TF-IDF com a similaridade do cosseno foi significativamente melhor em todos os casos. Assim, iremos utilizar essa métrica para calcular os resultados em todo o conjunto de dados além das 1000 amostras já utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = SimilarityMetric.TFIDF\n",
    "results_df, results_dict = evaluate_matching(df_cleaned, df_cleaned, metric, top_k=top_k)\n",
    "print(\"=\"* 100)\n",
    "print(f\"\\nResultados da Avaliação para a métrica: {metric.name}\"\n",
    "      f\"\\nTamanho do DataFrame de Resultados: {results_df.shape}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 Razão Social): {results_df['top_1_razaosocial_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 Nome Fantasia): {results_df['top_1_nomefantasia_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 CNPJ): {results_df['top_1_cnpj_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 Razão Social): {results_df['top_5_razaosocial_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 Nome Fantasia): {results_df['top_5_nomefantasia_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 CNPJ): {results_df['top_5_cnpj_pred'].sum()}\"\n",
    "      f\"\\nAcuracias:\\n\"\n",
    "      f\"Top 1 Razão Social: {results_df['top_1_razaosocial_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 1 Nome Fantasia: {results_df['top_1_nomefantasia_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 1 CNPJ: {results_df['top_1_cnpj_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 Razão Social: {results_df['top_5_razaosocial_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 Nome Fantasia: {results_df['top_5_nomefantasia_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 CNPJ: {results_df['top_5_cnpj_pred'].mean() * 100:.2f}%\")\n",
    "print(\"=\"* 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"tf-idf-results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Análise dos Erros de CNPJ\n",
    "\n",
    "Como observado acima, o `TextRetriever` implementado com o `TF-IDF` e `Cosine Similarity` apresentou os melhores resultados. Por outro lado, mesmo o TF-IDF nao obteve um resultado satisfatório para o `CNPJ` retornado no top 1 ou top 5, embora os resultados para a `razaosocial` e `nome_fantasia` nao tenham sido ruins.\n",
    "\n",
    "Vamos observar como os erros de CNPJ no top 5 se distribuem em relacao aos erros e acertos de `razaosocial` e `nome_fantasia`.\n",
    "\n",
    "Uma hipótese para o poeque isso acontece é que dentro de um mesmo estado/`uf` um mesmo par `razaosocial` e `nome_fantasia` pode ter diferentes `CNPJ`s, o que torna a tarefa de recuperação de `CNPJ` mais complexa mesmo quando se obtem o par `razaosocial` e `nome_fantasia` corretos. Para verificar se isso acontece, observemos como os erros de CNPJ se distribuem quando há acertos e/ou erros para a `razaosocial` e `nome_fantasia`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_top5_razao_nome = results_df[\n",
    "    (results_df['top_5_razaosocial_pred'] == False) & \n",
    "    (results_df['top_5_nomefantasia_pred'] == False) &\n",
    "    (results_df['top_5_cnpj_pred'] == False)\n",
    "]\n",
    "\n",
    "erro_top5_razao_acerto_nome = results_df[\n",
    "    (results_df['top_5_razaosocial_pred'] == False) & \n",
    "    (results_df['top_5_nomefantasia_pred'] == True) &\n",
    "    (results_df['top_5_cnpj_pred'] == False)\n",
    "]\n",
    "erro_top5_acerto_razao_nome = results_df[\n",
    "    (results_df['top_5_razaosocial_pred'] == True) & \n",
    "    (results_df['top_5_nomefantasia_pred'] == False) &\n",
    "    (results_df['top_5_cnpj_pred'] == False)\n",
    "]\n",
    "\n",
    "acerto_top5_razao_nome = results_df[\n",
    "    (results_df['top_5_razaosocial_pred'] == True) & \n",
    "    (results_df['top_5_nomefantasia_pred'] == True) &\n",
    "    (results_df['top_5_cnpj_pred'] == False)\n",
    "]\n",
    "\n",
    "total_cnpj_errors = results_df[\n",
    "    (results_df['top_5_cnpj_pred'] == False)\n",
    "]\n",
    "print(\"\\nDistribuição dos Erros de CNPJ:\")\n",
    "print(f\"\\nErro no Top 5 Razão Social e Nome Fantasia: {len(erro_top5_razao_nome)/len(total_cnpj_errors) * 100:.2f}%\")\n",
    "print(f\"Erro no Top 5 Razão Social e acerto no Top 5 Nome Fantasia: {len(erro_top5_razao_acerto_nome)/len(total_cnpj_errors) * 100:.2f}%\")\n",
    "print(f\"Acerto no Top 5 Razão Social e erro no Top 5 Nome Fantasia: {len(erro_top5_acerto_razao_nome)/len(total_cnpj_errors) * 100:.2f}%\")\n",
    "print(f\"Acerto no Top 5 Razão Social e Nome Fantasia: {len(acerto_top5_razao_nome)/len(total_cnpj_errors) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como verificado acima a maioria dos erros de CNPJ (aproximadamente **87%**) ocorre quando  houve acerto na `razaosocial` e/ou `nome_fantasia`, sendo que **65%** dos erros de CNPJ no top 5 ocorre em casos em que houve acerto de ambos `razaosocial` e `nome_fantasia`, mas o CNPJ retornado não é o correto. \n",
    "\n",
    "Isso ocorre provavelmente porque no conjunto de dados, em um mesmo estado (`uf`), há mais de uma empresa com os mesmos `razaosocial` e `nome_fantasia`. Verifiquemos se isso é verdade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnpj_counts_per_pair = df.groupby(['uf', 'razaosocial', 'nome_fantasia'])['cnpj'].nunique()\n",
    "\n",
    "total_records_per_uf = df.groupby('uf').size()\n",
    "\n",
    "multiple_cnpjs_summary = (\n",
    "    cnpj_counts_per_pair[cnpj_counts_per_pair > 1]\n",
    "    .reset_index()\n",
    "    .groupby('uf')\n",
    "    .agg({\n",
    "        'cnpj': ['count', 'mean', 'max']\n",
    "    })\n",
    ")\n",
    "multiple_cnpjs_summary.columns = ['pairs_with_multiple_cnpjs', 'avg_cnpjs_per_problematic_pair', 'max_cnpjs_per_pair']\n",
    "\n",
    "multiple_cnpjs_summary['total_records'] = total_records_per_uf\n",
    "\n",
    "records_in_multi_cnpj = (\n",
    "    df[df.groupby(['uf', 'razaosocial', 'nome_fantasia'])['cnpj'].transform('nunique') > 1]\n",
    "    .groupby('uf')\n",
    "    .size()\n",
    ")\n",
    "\n",
    "multiple_cnpjs_summary['records_in_multi_cnpj'] = records_in_multi_cnpj.reindex(multiple_cnpjs_summary.index, fill_value=0)\n",
    "\n",
    "multiple_cnpjs_summary['percentage_records_in_multi_cnpj'] = (\n",
    "    multiple_cnpjs_summary['records_in_multi_cnpj'] / \n",
    "    multiple_cnpjs_summary['total_records'] * 100\n",
    ").round(2)\n",
    "\n",
    "multiple_cnpjs_summary = multiple_cnpjs_summary[[\n",
    "    'pairs_with_multiple_cnpjs', \n",
    "    'percentage_records_in_multi_cnpj',\n",
    "    'records_in_multi_cnpj',\n",
    "    'total_records',\n",
    "]].round(2).sort_values('pairs_with_multiple_cnpjs', ascending=False)\n",
    "\n",
    "print(\"Summary of pairs with multiple CNPJs per UF:\")\n",
    "multiple_cnpjs_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tabela acima revela que em todos os `uf` presentes no conjunto de dados, há um número significativo de empresas com o mesmo `razaosocial` e `nome_fantasia`, mas com `CNPJ`s diferentes. \n",
    "\n",
    "A tarefa de recuperação de `CNPJ` de uma empresa em determinado estado (`uf`) necessita, entao, de mais informacoes alem da `razaosocial` e `nome_fantasia` da empresa buscada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Criacao de Retriever Utilizando Sentence Transformers\n",
    "\n",
    "Vamos implementar um retriever utilizando embeddings de sentenças.\n",
    "\n",
    " Serao gerados embeddings para as colunas `razaosocial_cleaned` e `nome_fantasia_cleaned`. Tais embeddings serão utilizados para calcular a similaridade entre o `user_input_cleaned` e as colunas mencionadas. A métrica de similaridade utilizada será a similaridade cosseno, que é uma métrica comum para medir a similaridade entre vetores de alta dimensão e é a mesma utilizada anteriormente para calcular a similaridade entre os vetores TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import Counter\n",
    "\n",
    "class SemanticRetrieval:\n",
    "    def __init__(self, df: pd.DataFrame, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.df = df.copy()\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.index = None\n",
    "        self.embeddings = None\n",
    "        self.id_map = None  # maps index -> df index\n",
    "        self._prepare_index()\n",
    "\n",
    "    def _prepare_index(self):\n",
    "        self.df['razaosocial_cleaned'] = self.df['razaosocial'].apply(comprehensive_text_cleaning)\n",
    "        self.df['nome_fantasia_cleaned'] = self.df['nome_fantasia'].apply(comprehensive_text_cleaning)\n",
    "        self.df['combined'] = (\n",
    "            self.df['razaosocial_cleaned'].fillna('') + ' ' +\n",
    "            self.df['nome_fantasia_cleaned'].fillna('')\n",
    "        )\n",
    "\n",
    "        # Compute embeddings\n",
    "        self.embeddings = self.model.encode(self.df['combined'].tolist(), show_progress_bar=True)\n",
    "        self.embeddings = np.array(self.embeddings).astype('float32')\n",
    "\n",
    "        # Create FAISS index\n",
    "        dimension = self.embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(dimension)\n",
    "        self.index.add(self.embeddings)\n",
    "\n",
    "        # Store mapping from index -> dataframe row\n",
    "        self.id_map = self.df.index.to_numpy()\n",
    "\n",
    "    def search(self, user_input: str, top_k: int = 5, uf: str = None) -> dict:\n",
    "        user_embedding = self.model.encode([user_input]).astype('float32')\n",
    "        distances, indices = self.index.search(user_embedding, top_k)\n",
    "\n",
    "        matched_rows = self.df.iloc[self.id_map[indices[0]]].copy()\n",
    "\n",
    "        if uf:\n",
    "            matched_rows = matched_rows[matched_rows['uf'] == uf]\n",
    "\n",
    "        cnpjs = matched_rows['cnpj'].dropna().tolist()\n",
    "        most_common_cnpjs = [cnpj for cnpj, _ in Counter(cnpjs).most_common(top_k)]\n",
    "\n",
    "        return {\n",
    "            'razaosocial': matched_rows['razaosocial'].tolist(),\n",
    "            'nome_fantasia': matched_rows['nome_fantasia'].tolist(),\n",
    "            'cnpjs': most_common_cnpjs,\n",
    "            'distances': distances[0].tolist()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_matching_semantic(df_sample, df_cleaned, top_k=5):\n",
    "    results = []\n",
    "    indexes = []\n",
    "    results_dict = {}\n",
    "\n",
    "    retrievers_by_uf = {}\n",
    "    for uf, group in df_cleaned.groupby('uf'):\n",
    "        group = group.drop_duplicates(subset=['razaosocial_cleaned', 'nome_fantasia_cleaned', 'cnpj'])\n",
    "        group = group.reset_index(drop=False) \n",
    "        retrievers_by_uf[uf] = SemanticRetrieval(group)\n",
    "\n",
    "    for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample), desc=\"Semantic Matching\"):\n",
    "        user_input = row['user_input_cleaned']\n",
    "        razaosocial = row['razaosocial_cleaned']\n",
    "        nome_fantasia = row['nome_fantasia_cleaned']\n",
    "        not_cleaned_user_input = row['user_input']\n",
    "        not_cleaned_razaosocial = row['razaosocial']\n",
    "        not_cleaned_nome_fantasia = row['nome_fantasia']\n",
    "        cnpj = row['cnpj']\n",
    "        uf = row['uf']\n",
    "\n",
    "        retriever = retrievers_by_uf.get(uf)\n",
    "        if retriever is None:\n",
    "            continue \n",
    "\n",
    "        result = retriever.search(user_input, top_k=top_k)\n",
    "\n",
    "        top_k_razao = result['razaosocial']\n",
    "        top_k_nome = result['nome_fantasia']\n",
    "        top_k_cnpj = result['cnpjs']\n",
    "\n",
    "        top_1_razao = top_k_razao[0] if top_k_razao else None\n",
    "        top_1_nome = top_k_nome[0] if top_k_nome else None\n",
    "        top_1_cnpj = top_k_cnpj[0] if top_k_cnpj else None\n",
    "\n",
    "        result_row = {\n",
    "            \"user_input\": user_input,\n",
    "            \"user_input_not_cleaned\": not_cleaned_user_input,\n",
    "            \"razaosocial_not_cleaned\": not_cleaned_razaosocial,\n",
    "            \"nome_fantasia_not_cleaned\": not_cleaned_nome_fantasia,\n",
    "            \"razaosocial\": razaosocial,\n",
    "            \"nome_fantasia\": nome_fantasia,\n",
    "            \"cnpj\": cnpj,\n",
    "            \"uf\": uf,\n",
    "            \n",
    "            \"top_1_razaosocial_retrieved\": top_1_razao,\n",
    "            \"top_1_nomefantasia_retrieved\": top_1_nome,\n",
    "            \"top_1_cnpj_retrieved\": top_1_cnpj,\n",
    "\n",
    "            \"top_1_razaosocial_pred\": top_1_razao == not_cleaned_razaosocial if top_1_razao else False,\n",
    "            \"top_1_nomefantasia_pred\": top_1_nome == not_cleaned_nome_fantasia if top_1_nome else False,\n",
    "            \"top_1_cnpj_pred\": top_1_cnpj == cnpj if top_1_cnpj else False,\n",
    "\n",
    "            \"top_5_razaosocial_pred\": not_cleaned_razaosocial in top_k_razao,\n",
    "            \"top_5_nomefantasia_pred\": not_cleaned_nome_fantasia in top_k_nome,\n",
    "            \"top_5_cnpj_pred\": cnpj in top_k_cnpj,\n",
    "        }\n",
    "\n",
    "        results_dict[idx] = result_row\n",
    "        results_dict[idx]['top_k_razaosocial_pred'] = top_k_razao\n",
    "        results_dict[idx]['top_k_nomefantasia_pred'] = top_k_nome\n",
    "        results_dict[idx]['top_k_cnpj_pred'] = top_k_cnpj\n",
    "\n",
    "        results.append(result_row)\n",
    "        indexes.append(idx)\n",
    "\n",
    "    results_df = pd.DataFrame(results, index=indexes)\n",
    "    return results_df, results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "top_k = 5\n",
    "if sample_size:\n",
    "    df_sample = df_cleaned.sample(n=sample_size, random_state=42)\n",
    "else:\n",
    "    df_sample = df_cleaned\n",
    "results_df, results_dict = evaluate_matching_semantic(df_sample, df_cleaned, top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nResultados da Avaliação:\"\n",
    "      f\"\\nTamanho do DataFrame de Resultados: {results_df.shape}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 Razão Social): {results_df['top_1_razaosocial_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 Nome Fantasia): {results_df['top_1_nomefantasia_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 CNPJ): {results_df['top_1_cnpj_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 Razão Social): {results_df['top_5_razaosocial_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 Nome Fantasia): {results_df['top_5_nomefantasia_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 CNPJ): {results_df['top_5_cnpj_pred'].sum()}\"\n",
    "      f\"\\nAcuracias:\\n\"\n",
    "      f\"Top 1 Razão Social: {results_df['top_1_razaosocial_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 1 Nome Fantasia: {results_df['top_1_nomefantasia_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 1 CNPJ: {results_df['top_1_cnpj_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 Razão Social: {results_df['top_5_razaosocial_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 Nome Fantasia: {results_df['top_5_nomefantasia_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 CNPJ: {results_df['top_5_cnpj_pred'].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um subconjunto de 1000 amostras do conjunto de dados, um modelo de sentence transformer nao tunado nao obteve um resultado satisfatório quando comparado ao retriever com TF-IDF. Portanto, por ora, considera-se a melhor solucao como sendo o retriever que utiliza o TF-IDF e a similaridade do cosseno."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
