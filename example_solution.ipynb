{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amostra de Solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo os imports, para carregar um modelo de embedding do Hugging Face para português, e o dataset de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darth\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "confs = yaml.safe_load(open(\"confs.yaml\"))\n",
    "predictors = confs[\"predictors\"] ### Importante! O cientista poderá usar apenas estas features para criar/aperfeiçoar o modelo\n",
    "text_target = confs[\"text_target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando uma amostra do dataset para mostrar o que é esperado do case em questão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = 2000 # Para mostrar o que é esperado\n",
    "\n",
    "train = pd.read_parquet(\"dados/train.parquet\").iloc[:SAMPLE]\n",
    "X_train, y_train = train[predictors], train[text_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega o [modelo de embeddings](https://huggingface.co/ricardo-filho/bert-base-portuguese-cased-nli-assin-2) Bi-Encoder (BERT) para o português."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darth\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"ricardo-filho/bert-base-portuguese-cased-nli-assin-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [01:05<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "y_train_sentences = y_train.apply(lambda x: \" - \".join(x), axis=1).tolist()\n",
    "y_train_embeddings = model.encode(\n",
    "    y_train_sentences, show_progress_bar=True, device=\"cuda\", batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [01:10<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "X_train_sentences = X_train.apply(lambda x: \" - \".join(x), axis=1).tolist()\n",
    "X_train_embeddings = model.encode(\n",
    "    X_train_sentences, show_progress_bar=True, device=\"cuda\", batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darth\\AppData\\Local\\Temp\\ipykernel_6172\\2480415732.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[\"prediction\"] = y_train.apply(lambda x: \" - \".join(x), axis=1).iloc[\n",
      "C:\\Users\\darth\\AppData\\Local\\Temp\\ipykernel_6172\\2480415732.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[\"target\"] = y_train.apply(lambda x: \" - \".join(x), axis=1).tolist()\n"
     ]
    }
   ],
   "source": [
    "X_train[\"prediction\"] = y_train.apply(lambda x: \" - \".join(x), axis=1).iloc[\n",
    "    model.similarity(X_train_embeddings, y_train_embeddings).argmax(axis=1)\n",
    "].tolist()\n",
    "X_train[\"target\"] = y_train.apply(lambda x: \" - \".join(x), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "Computando a performance do modelo nesse pequeno Sample do dataset de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darth\\AppData\\Local\\Temp\\ipykernel_6172\\1044487981.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  performance_df[\"correct\"] = performance_df[\"prediction\"] == performance_df[\"target\"]\n"
     ]
    }
   ],
   "source": [
    "performance_df = X_train[[\"prediction\", \"target\"]]\n",
    "performance_df[\"correct\"] = performance_df[\"prediction\"] == performance_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 Precision: 17.55%\n"
     ]
    }
   ],
   "source": [
    "top_1_precision = performance_df[\"correct\"].mean()\n",
    "print(f\"Top 1 Precision: {top_1_precision:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importante!\n",
    "\n",
    "Naturalmente é esperado a performance no dataset de treino completo e não apenas na amostra (2000 casos). O dataset de teste não será fornecido para o cientista, pois o será utilizado para avaliar a performance do modelo treinado (ou *fine-tunado*) para este case.\n",
    "\n",
    "Para mais informações sobre o case, veja o README.md do repositório."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
