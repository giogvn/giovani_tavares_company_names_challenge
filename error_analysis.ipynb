{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import re\n",
    "import Levenshtein\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from jiwer import wer, cer\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, Union, Set, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Levenshtein\n",
    "from functools import wraps\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carregando os Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = yaml.safe_load(open(\"confs.yaml\"))\n",
    "predictors = confs[\"predictors\"] ### Importante! O cientista poderá usar apenas estas features para criar/aperfeiçoar o modelo\n",
    "text_target = confs[\"text_target\"]\n",
    "cols_to_keep = predictors + text_target + ['cnpj']\n",
    "df = pd.read_parquet(\"dados/train.parquet\")[cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparando os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Presenca de Valores `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores NaN por coluna:\n",
      "user_input       0\n",
      "uf               0\n",
      "razaosocial      0\n",
      "nome_fantasia    0\n",
      "cnpj             0\n",
      "dtype: int64\n",
      "\n",
      "Total de linhas com algum valor NaN: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValores NaN por coluna:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nTotal de linhas com algum valor NaN: {df.isnull().any(axis=1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nenhuma das colunas do conjunto de dados fornecido possui algum valor `NaN`, nao será necessária a realizacao de nenhum tratamento desse tipo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Presenca de Linhas Duplicadas\n",
    "\n",
    "Linhas duplicadas em relacao a todas as colunas do conjunto de dados serao removidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas duplicadas: 406\n"
     ]
    }
   ],
   "source": [
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Número de linhas duplicadas: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto original: (255471, 5)\n",
      "Tamanho do conjunto após remocao de linhas duplicadas em relacao a todas as colunas: (255065, 5)\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "print(f\"Tamanho do conjunto original: {df.shape}\")\n",
    "print(f\"Tamanho do conjunto após remocao de linhas duplicadas em relacao a todas as colunas: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Remocao de Termos Irrelevantes\n",
    "\n",
    "Colunas com o sufixo `_cleaned` serao criadas para as colunas `user_input`, `razaosocial` e `nome_fantasia`. Nelas, termos como \"S.A.\", \"LTDA\", \"LTDA.\", \"S/A\", \"S.A\", \"Ltda\", \"Ltda.\", \"S/A.\", \"S.A.\", \"S.A\", \"Ltda\" e \"Ltda\" serao removidos baseados na seguinte suposicao:\n",
    "\n",
    " > **Usuários nao tem o hábito de utilizar esses termos ao se referir a nomes de empresas, então elas não devem ser consideradas na busca/retrieval**\n",
    "\n",
    "\n",
    "Essa remocao é importante, pois ao se calcular a similaridade entre um `user_input` e/ou `razaosocial` e `nome_fantasia`, as métricas de similaridade seriam prejudicadas na ausencia de tais termos no `user_input`. \n",
    "\n",
    "Também serao removidas acentos e stopwords da língua portuguesa, sobretudo preposicoes. Tais termos, por nao informarem sobre empresas específicas, podem prejudicar a acurácia das buscas/retrieval.\n",
    "Além disso, passaremos tudo para letras minúsculas, para evitar problemas de case-sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_text_cleaning(text, \n",
    "                               remove_accents=True,\n",
    "                               remove_stop_words=True, \n",
    "                               remove_company_suffixes=True,\n",
    "                               custom_stop_words=None,\n",
    "                               to_lowercase=True):\n",
    "    \"\"\"\n",
    "    Comprehensive text cleaning function\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): Input text\n",
    "    remove_accents (bool): Remove accents and normalize characters\n",
    "    remove_stop_words (bool): Remove Portuguese stop words\n",
    "    remove_company_suffixes (bool): Remove common company suffixes\n",
    "    custom_stop_words (set): Additional stop words to remove\n",
    "    to_lowercase (bool): Convert to lowercase\n",
    "    \n",
    "    Returns:\n",
    "    str: Cleaned text\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    if remove_accents:\n",
    "        text = unicodedata.normalize('NFD', text)\n",
    "        text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')\n",
    "        text = text.replace('ç', 'c').replace('Ç', 'C')\n",
    "    \n",
    "    if to_lowercase:\n",
    "        text = text.lower()\n",
    "    \n",
    "    if remove_company_suffixes:\n",
    "        patterns_to_remove = [\n",
    "        r'\\bS\\.?A\\.?\\b',           # S.A, SA, S.A., SA.\n",
    "        r'\\bS/A\\.?\\b',             # S/A, S/A.\n",
    "        r'\\bLTDA\\.?\\b',            # LTDA, LTDA.\n",
    "        r'\\bLIMITADA\\b',           # LIMITADA\n",
    "        r'\\bCIA\\.?\\b',             # CIA, CIA.\n",
    "        r'\\bCOMPANHIA\\b',          # COMPANHIA\n",
    "        r'\\bEMPRESA\\b',            # EMPRESA\n",
    "        r'\\bCOMERCIO\\b',           # COMERCIO\n",
    "        r'\\bSERVICOS?\\b',          # SERVICO, SERVICOS\n",
    "        r'\\bME\\b',                 # ME (Microempresa)\n",
    "        r'\\bEPP\\b',                # EPP (Empresa de Pequeno Porte)\n",
    "        r'\\bEIRELI\\b',             # EIRELI\n",
    "        r'\\bSOCIEDADE\\b',          # SOCIEDADE\n",
    "        r'ADMINISTRADORA\\b',       # ADMINISTRADORA\n",
    "        r'GERAL\\b',                # GERAL\n",
    "    ]\n",
    "        \n",
    "        for pattern in patterns_to_remove:\n",
    "            text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    if remove_stop_words:\n",
    "        portuguese_stop_words = {\n",
    "            'a', 'ao', 'aos', 'as', 'da', 'das', 'de', 'do', 'dos', 'e', 'em', 'na', \n",
    "            'nas', 'no', 'nos', 'o', 'os', 'para', 'por', 'com', 'um', 'uma', 'uns', \n",
    "            'umas', 'se', 'que', 'ou', 'mas', 'como', 'mais', 'muito', 'sua', 'seu',\n",
    "            'seus', 'suas', 'este', 'esta', 'estes', 'estas', 'esse', 'essa', 'esses',\n",
    "            'essas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'isso', 'aquilo'\n",
    "        }\n",
    "        \n",
    "        if custom_stop_words:\n",
    "            portuguese_stop_words.update(custom_stop_words)\n",
    "        \n",
    "        words = text.split()\n",
    "        words = [word for word in words if word.lower() not in portuguese_stop_words]\n",
    "        text = ' '.join(words)\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)      # Multiple spaces to single space\n",
    "    text = text.strip()                   # Remove leading/trailing spaces\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['user_input_cleaned'] = df['user_input'].apply(comprehensive_text_cleaning)\n",
    "df_cleaned['razaosocial_cleaned'] = df['razaosocial'].apply(comprehensive_text_cleaning)\n",
    "df_cleaned['nome_fantasia_cleaned'] = df['nome_fantasia'].apply(comprehensive_text_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Definicao do Retriever\n",
    "\n",
    "A tarefa é baseada em recuperar a **razaosocial** e o **nome_fantasia** (outputs) de uma determinada companhia a partir de um **user_input** e um **uf** correspondente ao estado de onde vem aquele input de usuário. Para isso, um bom retriever deve ser capaz de encontrar a **razaosocial** e o **nome_fantasia** de menor *diferenca* com o **user_input**. \n",
    "\n",
    "Abstratamente, essa *diferenca* pode ser calculada de duas maneiras distintas:\n",
    "\n",
    ">  **Métodos Clássicos:** **user_input**, **razaosocial** e o **nome_fantasia** comparados no espaco das strings. Nesse caso, métricas de comparacao de strings sao utilizadas de modo que o retriever retorne a **razaosocial** e o **nome_fantasia** mais similares ao **user_input**. Tais métricas nao capturam diferencas sintáticas das strings sendo comparadas, mas apenas diferencas de caracteres e/ou palavras.\n",
    "\n",
    "\n",
    "> **Sentence Transformers**: **user_input**, **razaosocial** e o **nome_fantasia** comparados em um espaco vetorial comum. Nesse caso, as sentencas de texto sendo comparadas sao primeiro transformadas em um vetor por um Sentence Transformer antes de serem comparadas. Essa transformacao é tal que captura a informacao contextual e semantica das strings sendo comparadas além das diferencas a nível de caracteres e/ou palavras. \n",
    "\n",
    "Dois retrievers serao construídos, sendo um que utiliza os métodos clássicos e outro que utiliza um Sentence Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Retriever com Métodos Clássicos \n",
    "\n",
    "As seguintes métricas de similaridade e erro entre strings a nível de caracter serao implementadas:\n",
    "\n",
    "***\n",
    "> ## Word Error Rate (WER): \n",
    "\n",
    " Calcula a taxa de erro a nível de palavras: \n",
    "  $$WER = \\frac{S + D + I}{N}$$\n",
    "  onde:\n",
    "  - $S$ é o número de substituições. Por exemplo, se o usuário digitou \"Empresa X\" e a referência é \"Empresa Y\", então há uma substituição.\n",
    "  - $D$ é o número de deleções. Por exemplo, se o usuário digitou \"Empresa\" e a referência é \"Empresa X\", então há uma deleção.\n",
    "  - $I$ é o número de inserções. Por exemplo, se o usuário digitou \"Empresa X Y\" e a referência é \"Empresa X\", então há uma inserção.\n",
    "  - $N$ é o número total de palavras na referência. Por exemplo, se a referência é \"Empresa X\", então $N$ é 2.\n",
    "\n",
    "***\n",
    "> ## Character Error Rate (CER): \n",
    "\n",
    "Calcula a taxa de erro a nível de caracteres:\n",
    "  $$CER = \\frac{S + D + I}{N}$$\n",
    "  onde:\n",
    "  - $S$ é o número de substituições. Por exemplo, se o usuário digitou \"EmpresaXY\" e a referência é \"EmpresaXZ\", então há uma substituição.\n",
    "  - $D$ é o número de deleções. Por exemplo, se o usuário digitou \"Empresa\" e a referência é \"EmpresaX\", então há uma deleção.\n",
    "  - $I$ é o número de inserções. Por exemplo, se o usuário digitou \"Empresa XY\" e a referência é \"Empresa X\", então há uma inserção.\n",
    "  - $N$ é o número total de caracteres na referência. Por exemplo, se a referência é \"Empresa X\", então $N$ é 9 (contando espaços).\n",
    "\n",
    "***\n",
    "> ## Distância de Levenshtein Normalizada: \n",
    "\n",
    "Mede a diferença entre duas sequências de caracteres. É definida como o número mínimo de operações de edição (inserções, deleções ou substituições) necessárias para transformar uma palavra em outra. A normalização é feita dividindo a distância pelo comprimento da maior palavra entre as comparadas:\n",
    "  $$D(A, B) = \\frac{L(A, B)}{max(|A|, |B|)}$$\n",
    "  onde $L(A, B)$ é a distância de Levenshtein entre as sequências $A$ e $B$, e $|A|$ e $|B|$ são os comprimentos das sequências.\n",
    "\n",
    "  Por exemplo, se temos o texto \"empresa X\" e \"empresa Y\", a distância de Levenshtein seria 1 (substituindo \"X\" por \"Y\"). A normalização seria:\n",
    "  $$D(\\text{\"empresa X\"}, \\text{\"empresa Y\"}) = \\frac{1}{9}$$\n",
    "\n",
    "***\n",
    "> ## Similaridade de Jaccard: \n",
    "\n",
    "Mede a similaridade entre dois conjuntos. É definida como o tamanho da interseção dividido pelo tamanho da união dos conjuntos.\n",
    "  $$J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}$$\n",
    "\n",
    "  No caso de textos, podemos considerar conjuntos de palavras ou caracteres. Por exemplo, se temos dois textos \"empresa X\" e \"empresa Y\", podemos considerar os conjuntos de palavras {empresa, X} e {empresa, Y}. A similaridade de Jaccard seria calculada como:\n",
    "  $$J(\\{empresa, X\\}, \\{empresa, Y\\}) = \\frac{|\\{empresa\\}|}{|\\{empresa, X, Y\\}|} = \\frac{1}{3}$$\n",
    "\n",
    "***\n",
    "> ## Similaridade de Jaccard N Gram: \n",
    "\n",
    "É uma extensão da similaridade de Jaccard que considera n-gramas (sequências de n itens contíguos) em vez de palavras ou caracteres individuais. É útil para capturar similaridades em sequências mais longas, como frases ou sentenças. \n",
    "  A fórmula é semelhante à similaridade de Jaccard, mas aplicada a n-gramas:\n",
    "  $$J(A, B) = \\frac{|A_n \\cap B_n|}{|A_n \\cup B_n|}$$\n",
    "\n",
    "No caso de textos, se temos o texto \"empresa X\", seus dois-gramas seriam {\"em\", \"mp\", \"pr\", \"re\", \"sa\", \"a \", \" X\"}. Seus três-gramas seriam {\"emp\", \"mpr\", \"pre\", \"res\", \"esa\", \"sa \", \"a X\"} e assim por diante. A similaridade de Jaccard N Gram seria calculada considerando esses n-gramas.\n",
    "\n",
    "Ela é útil para capturar similaridades em casos de comparação de textos com erros de digitação, com pequenas inversoes/omissoes de caracteres, como ao comparar \"emprEsa X\" e \"emprsa X\", onde a ordem dos caracteres é preservada, mas algumas letras estão fora de lugar.\n",
    "\n",
    "***\n",
    "> ## Similaridade de Jaccard Multi N Gram: \n",
    "\n",
    "É uma extensão da similaridade de Jaccard N Gram que considera múltiplos tamanhos de n-gramas. A métrica final é calculada como a média ponderada das similaridades de Jaccard para diferentes tamanhos de n-gramas. Isso permite capturar similaridades em diferentes níveis de granularidade, desde caracteres individuais até sequências mais longas.\n",
    "\n",
    "> ## TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "\n",
    "É uma técnica de pontuação que mede a importância relativa de palavras em documentos. No contexto de matching entre input do usuário e registros de nome_fantasia/razao_social, o TF-IDF ajuda a identificar quais termos são mais distintivos para cada empresa, priorizando palavras raras e específicas sobre termos genéricos comuns.\n",
    "\n",
    "A fórmula combina dois componentes:\n",
    "\n",
    "**TF (Term Frequency):**\n",
    "$$TF(t,d) = \\frac{\\text{número de ocorrências do termo t no nome de empresa d}}{\\text{número total de termos no nome de empresa d}}$$\n",
    "\n",
    "**IDF (Inverse Document Frequency):**\n",
    "$$IDF(t,D) = \\log\\left(\\frac{\\text{número total de nomes distintos de empresas no corpus}}{\\text{número de nomes de empresas que contêm o termo t}}\\right)$$\n",
    "\n",
    "**TF-IDF final:**\n",
    "$$TF\\text{-}IDF(t,d,D) = TF(t,d) \\times IDF(t,D)$$\n",
    "\n",
    "**Onde:**\n",
    "- **t** = termo/palavra específica (ex: \"Petrobras\", \"S.A.\", \"Banco\")\n",
    "- **d** = no caso do problema, a razao social de uma empresa concatenada com seu nome fantasia, separados por um espaco (ex: \"Apple Inc. Apple\")\n",
    "- **D** = corpus completo com os nomes de todas as empresas definidas como o **d** acima.\n",
    "\n",
    "**Vetor Final:**\n",
    "Para cada nome de empresa **d**, o vetor TF-IDF tem dimensão igual ao número $n$ de termos únicos que formam todos os nomes de empresas no corpus $D$, onde cada posição representa o score TF-IDF de um termo:\n",
    "$$\\vec{v_d} = [TF\\text{-}IDF(t_1,d,D), TF\\text{-}IDF(t_2,d,D), ..., TF\\text{-}IDF(t_n,d,D)]$$\n",
    "\n",
    "O resultado desse processo é um **índice de vetores** em que cada um representa uma empresa específica. \n",
    "\n",
    "Termos raros em relacao a todos os nomes de empresas disponíveis com excecao daquela empresa a qual o termo se refere terao IDF grandes. Por exemplo, suponha que **D** é formado por nomes de empresas como \"Petrobras S.A.\", \"Magazine Luiza S.A.\" e \"Banco do Brasil S.A.\". Nesse caso, a palavra \"S.A.\" aparece em muitas empresas, fazendo que seu IDF seja baixo nos vetores $\\vec{v_d}$ todos os nomes de empresas e, portanto, nao tendo relevancia para distinguir nomes de empresas distintas.\n",
    "\n",
    "\"Petrobras\" aparece no nome de uma única empresa, portanto terá IDF alto. Quando o usuário digita \"petrobras\", o seu vetor TF-IDF é calculado para todos os nomes de empresas $d$ e o nome de empresa $d$ correspondente retornado pelo retriever é o aquele cujo vetor $\\vec{v_d}$ é o mais similar ao vetor correspondente ao input do usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "import Levenshtein\n",
    "from jiwer import cer, wer\n",
    "\n",
    "class TextMetrics:\n",
    "    \"\"\"\n",
    "    A class containing various text comparison metrics with input validation.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_cer(reference: str, hypothesis: str) -> float:\n",
    "        \"\"\"Calculate Character Error Rate.\"\"\"\n",
    "        if not reference or not hypothesis:\n",
    "            return 1.0  # Worst case: 100% error\n",
    "        return cer(reference, hypothesis)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_wer(reference: str, hypothesis: str) -> float:\n",
    "        \"\"\"Calculate Word Error Rate.\"\"\"\n",
    "        if not reference or not hypothesis:\n",
    "            return 1.0  # Worst case: 100% error\n",
    "        return wer(reference, hypothesis)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_normalized_levenshtein(reference: str, hypothesis: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate normalized Levenshtein distance (0-1).\n",
    "        Returns:\n",
    "            float: Normalized Levenshtein distance between 0 and 1\n",
    "        \"\"\"\n",
    "        if not reference or not hypothesis:\n",
    "            return 1.0  # Worst case: maximum distance\n",
    "        max_len = max(len(reference), len(hypothesis))\n",
    "        if max_len == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        distance = Levenshtein.distance(reference, hypothesis)\n",
    "        return distance / max_len\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_character_set(text: str) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Convert text to a set of characters.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text\n",
    "            \n",
    "        Returns:\n",
    "            Set[str]: Set of characters from the input text\n",
    "        \"\"\"\n",
    "        return set(text)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_word_set(text: str) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Convert text to a set of words.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text\n",
    "            \n",
    "        Returns:\n",
    "            Set[str]: Set of words from the input text\n",
    "        \"\"\"\n",
    "        return set(text.lower().split())\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_jaccard_similarity(set1: Set[str], set2: Set[str]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Jaccard similarity between two sets.\n",
    "        \n",
    "        Args:\n",
    "            set1 (Set[str]): First set\n",
    "            set2 (Set[str]): Second set\n",
    "            \n",
    "        Returns:\n",
    "            float: Jaccard similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        if not set1 and not set2:  # Both sets are empty\n",
    "            return 1.0\n",
    "        if not set1 or not set2:   # One set is empty\n",
    "            return 0.0\n",
    "            \n",
    "        intersection = len(set1.intersection(set2))\n",
    "        union = len(set1.union(set2))\n",
    "        return intersection / union\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_jaccard_similarity_chars(reference: str, hypothesis: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Jaccard similarity based on character sets.\n",
    "        \n",
    "        Args:\n",
    "            reference (str): Reference text\n",
    "            hypothesis (str): Hypothesis text\n",
    "            \n",
    "        Returns:\n",
    "            float: Jaccard similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        if not reference or not hypothesis:\n",
    "            return 0.0  # Worst case: no similarity\n",
    "        ref_chars = TextMetrics._get_character_set(reference)\n",
    "        hyp_chars = TextMetrics._get_character_set(hypothesis)\n",
    "        return TextMetrics._calculate_jaccard_similarity(ref_chars, hyp_chars)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_jaccard_similarity_words(reference: str, hypothesis: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Jaccard similarity based on word sets.\n",
    "        \n",
    "        Args:\n",
    "            reference (str): Reference text\n",
    "            hypothesis (str): Hypothesis text\n",
    "            \n",
    "        Returns:\n",
    "            float: Jaccard similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        if not reference or not hypothesis:\n",
    "            return 0.0  # Worst case: no similarity\n",
    "        ref_words = TextMetrics._get_word_set(reference)\n",
    "        hyp_words = TextMetrics._get_word_set(hypothesis)\n",
    "        return TextMetrics._calculate_jaccard_similarity(ref_words, hyp_words)\n",
    "\n",
    "    @staticmethod \n",
    "    def _ngram_jaccard_similarity(reference: str, hypothesis: str, n=2):\n",
    "        \"\"\"\n",
    "        Calculate Jaccard similarity using character n-grams.\n",
    "        This handles inversions and some misspellings well.\n",
    "        \n",
    "        Args:\n",
    "            reference, hypothesis: Input strings\n",
    "            n: N-gram size (2=bigrams, 3=trigrams, etc.)\n",
    "        \"\"\"\n",
    "        if not reference or not hypothesis:\n",
    "            return 0.0  # Worst case: no similarity\n",
    "\n",
    "        def get_ngrams(text, n):\n",
    "            \"\"\"Generate n-grams from text with padding.\"\"\"\n",
    "            # Add padding to capture beginning/end patterns\n",
    "            padded = '#' * (n-1) + text.lower() + '#' * (n-1)\n",
    "            return set(padded[i:i+n] for i in range(len(padded) - n + 1))\n",
    "        \n",
    "        ngrams1 = get_ngrams(reference, n)\n",
    "        ngrams2 = get_ngrams(hypothesis, n)\n",
    "        \n",
    "        intersection = len(ngrams1 & ngrams2)\n",
    "        union = len(ngrams1 | ngrams2)\n",
    "        \n",
    "        return intersection / union if union > 0 else 1.0 if len(reference) == len(hypothesis) == 0 else 0.0\n",
    " \n",
    "    @staticmethod\n",
    "    def multi_ngram_jaccard_similarity(reference: str, hypothesis: str, ngram_sizes=[2, 3], weights=None):\n",
    "        \"\"\"\n",
    "        Combine multiple n-gram sizes for better robustness.\n",
    "        \"\"\"\n",
    "        if not reference or not hypothesis:\n",
    "            return 0.0  # Worst case: no similarity\n",
    "\n",
    "        if weights is None:\n",
    "            weights = [1.0] * len(ngram_sizes)\n",
    "        \n",
    "        if len(weights) != len(ngram_sizes):\n",
    "            raise ValueError(\"Number of weights must match number of n-gram sizes\")\n",
    "        \n",
    "        total_score = 0\n",
    "        total_weight = sum(weights)\n",
    "        \n",
    "        for size, weight in zip(ngram_sizes, weights):\n",
    "            score = TextMetrics._ngram_jaccard_similarity(reference, hypothesis, size)\n",
    "            total_score += score * weight\n",
    "        \n",
    "        return total_score / total_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Implementação do Retriever\n",
    "\n",
    "O retriever será implementado na classe `TextRetriever`.\n",
    "\n",
    "O método `TextRetrieval.find_best_matches` recebe um `user_input` e retorna os `k` `razaosocial` e `nome_fantasia` mais similares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Callable\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class SimilarityMetric(Enum):\n",
    "    CER = \"cer\"\n",
    "    WER = \"wer\"\n",
    "    LEVENSHTEIN = \"levenshtein\"\n",
    "    JACCARD_CHARS = \"jaccard_chars\"\n",
    "    JACCARD_WORDS = \"jaccard_words\"\n",
    "    NGRAM_JACCARD = \"ngram_jaccard\"\n",
    "    TFIDF = \"tfidf\"\n",
    "\n",
    "\n",
    "class TextRetrieval:\n",
    "    \"\"\"\n",
    "    A class for text retrieval using similarity metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    _tfidf_cache = {}\n",
    "    \n",
    "    # The values of this dictionary are tuples in which the index 1 holds\n",
    "    # a boolean that tells whether a metric is such that the higher \n",
    "    # its value the more similar the strings being compared are\n",
    "    _METRIC_CONFIG = {\n",
    "        SimilarityMetric.CER: (TextMetrics.calculate_cer, False),\n",
    "        SimilarityMetric.WER: (TextMetrics.calculate_wer, False),\n",
    "        SimilarityMetric.LEVENSHTEIN: (TextMetrics.calculate_normalized_levenshtein, False),\n",
    "        SimilarityMetric.JACCARD_CHARS: (TextMetrics.calculate_jaccard_similarity_chars, True),\n",
    "        SimilarityMetric.JACCARD_WORDS: (TextMetrics.calculate_jaccard_similarity_words, True),\n",
    "        SimilarityMetric.NGRAM_JACCARD: (\n",
    "            lambda text1, text2: TextMetrics.multi_ngram_jaccard_similarity(\n",
    "                text1, text2, ngram_sizes=[2, 3], weights=[0.5, 0.5]\n",
    "            ), \n",
    "            True\n",
    "        ),\n",
    "        SimilarityMetric.TFIDF: (None, True),  # handled separately\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_tfidf_cache_key(df: pd.DataFrame) -> str:\n",
    "        return str(hash(pd.util.hash_pandas_object(df[[\"razaosocial_cleaned\", \"nome_fantasia_cleaned\"]], index=False).sum()))\n",
    "\n",
    "    @classmethod\n",
    "    def _get_tfidf_cache(cls, df: pd.DataFrame):\n",
    "        key = cls._get_tfidf_cache_key(df)\n",
    "        if key not in cls._tfidf_cache:\n",
    "            combined = (\n",
    "                df[\"razaosocial_cleaned\"].fillna('') + ' ' + df[\"nome_fantasia_cleaned\"].fillna('')\n",
    "            )\n",
    "            vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 4))\n",
    "            tfidf_matrix = vectorizer.fit_transform(combined)\n",
    "            cls._tfidf_cache[key] = (vectorizer, tfidf_matrix, combined)\n",
    "        return cls._tfidf_cache[key]\n",
    "\n",
    "    @staticmethod\n",
    "    def _retrieve_topk_cnpjs_from_pairs(\n",
    "        df: pd.DataFrame,\n",
    "        razao_social_list: List[str],\n",
    "        nome_fantasia_list: List[str],\n",
    "        cnpj_col: str = \"cnpj\",\n",
    "        not_cleaned_razao_col: str = \"razaosocial\",\n",
    "        not_cleaned_fantasia_col: str = \"nome_fantasia\",\n",
    "        top_k: int = 5\n",
    "    ) -> List[str]:\n",
    "        assert len(razao_social_list) == len(nome_fantasia_list)\n",
    "        mask = pd.Series(False, index=df.index)\n",
    "        for razao, fantasia in zip(razao_social_list, nome_fantasia_list):\n",
    "            mask |= ((df[not_cleaned_razao_col] == razao) & (df[not_cleaned_fantasia_col] == fantasia))\n",
    "        cnpjs = df[mask][cnpj_col].dropna().tolist()\n",
    "        most_common = Counter(cnpjs).most_common(top_k)\n",
    "        return [cnpj for cnpj, _ in most_common]\n",
    "\n",
    "    @classmethod\n",
    "    def find_best_matches(\n",
    "        cls,\n",
    "        user_input: str, \n",
    "        df: pd.DataFrame, \n",
    "        metric: SimilarityMetric, \n",
    "        top_k: int = 1\n",
    "    ) -> Tuple[List[str], List[str], List[float], List[float], List[str]]:\n",
    "\n",
    "        if metric == SimilarityMetric.TFIDF:\n",
    "            return cls._find_matches_tfidf(user_input, df, top_k)\n",
    "\n",
    "        if metric not in cls._METRIC_CONFIG:\n",
    "            raise ValueError(f\"Unsupported metric: {metric}\")\n",
    "        \n",
    "        metric_func, reverse_sort = cls._METRIC_CONFIG[metric]\n",
    "\n",
    "        return cls._find_matches_with_metric(\n",
    "            user_input, df, metric_func, reverse_sort, top_k\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _find_matches_tfidf(\n",
    "        cls,\n",
    "        user_input: str,\n",
    "        df: pd.DataFrame,\n",
    "        top_k: int,\n",
    "        not_cleaned_razao_col: str = \"razaosocial\",\n",
    "        not_cleaned_fantasia_col: str = \"nome_fantasia\",\n",
    "        cnpj_col: str = \"cnpj\"\n",
    "    ) -> Tuple[List[str], List[str], List[str]]:\n",
    "\n",
    "        vectorizer, tfidf_matrix, combined_col = cls._get_tfidf_cache(df)\n",
    "        query_vec = vectorizer.transform([user_input])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "        best_razao_matches = df.iloc[top_indices][not_cleaned_razao_col].tolist()\n",
    "        best_nome_fantasia_matches = df.iloc[top_indices][not_cleaned_fantasia_col].tolist()\n",
    "        best_cnpj_matches =  df.iloc[top_indices][cnpj_col].tolist()\n",
    "\n",
    "        return (\n",
    "            best_razao_matches,\n",
    "            best_nome_fantasia_matches,\n",
    "            best_cnpj_matches,\n",
    "            )\n",
    "\n",
    "    @classmethod\n",
    "    def _find_matches_with_metric(\n",
    "        cls,\n",
    "        user_input: str,\n",
    "        df: pd.DataFrame,\n",
    "        metric_func: Callable[[str, str], float],\n",
    "        reverse_sort: bool,\n",
    "        top_k: int,\n",
    "        razao_col: str = \"razaosocial_cleaned\",\n",
    "        fantasia_col: str = \"nome_fantasia_cleaned\",\n",
    "        not_cleaned_razao_col: str = \"razaosocial\",\n",
    "        not_cleaned_fantasia_col: str = \"nome_fantasia\",\n",
    "    ) -> Tuple[List[str], List[str], List[float], List[float], List[str]]:\n",
    "\n",
    "        valid_mask = ~(df[razao_col].isna() & df[fantasia_col].isna())\n",
    "        if not valid_mask.any():\n",
    "            return [], [], [], [], []\n",
    "\n",
    "        df_valid = df[valid_mask].copy()\n",
    "\n",
    "        razao_scores = df_valid[razao_col].apply(\n",
    "            lambda x: metric_func(x, user_input) if pd.notna(x) else None\n",
    "        )\n",
    "        nome_scores = df_valid[fantasia_col].apply(\n",
    "            lambda x: metric_func(x, user_input) if pd.notna(x) else None\n",
    "        )\n",
    "\n",
    "        if reverse_sort:\n",
    "            max_scores = np.maximum(\n",
    "                razao_scores.fillna(-np.inf), \n",
    "                nome_scores.fillna(-np.inf)\n",
    "            )\n",
    "        else:\n",
    "            max_scores = np.minimum(\n",
    "                razao_scores.fillna(np.inf), \n",
    "                nome_scores.fillna(np.inf)\n",
    "            )\n",
    "\n",
    "        sorted_indices = np.argsort(max_scores)\n",
    "        if reverse_sort:\n",
    "            sorted_indices = sorted_indices[::-1]\n",
    "\n",
    "        top_indices = sorted_indices[:top_k]\n",
    "        best_razao_matches = df_valid.iloc[top_indices][not_cleaned_razao_col].tolist()\n",
    "        best_nome_fantasia_matches = df_valid.iloc[top_indices][not_cleaned_fantasia_col].tolist()\n",
    "        best_cnpj_matches = cls._retrieve_topk_cnpjs_from_pairs(\n",
    "            df_valid,\n",
    "            best_razao_matches,\n",
    "            best_nome_fantasia_matches,\n",
    "            top_k=top_k\n",
    "        )\n",
    "\n",
    "        return best_razao_matches, best_nome_fantasia_matches, best_cnpj_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Escolha da Melhor Métrica\n",
    "\n",
    "\n",
    "Serao sorteadas `1000` linhas do conjunto de dados para calcular as métricas de similaridade e erro.\n",
    "\n",
    " Para cada linha, vamos calcular todas as métricas de similaridade mencionadas acima entre o `user_input_cleaned` e as colunas `razaosocial_cleaned` e `nome_fantasia_cleaned`. A métrica escolhida será aquela que apresentar o menor valor de erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_matching(df_sample: pd.DataFrame,\n",
    "                      df_cleaned: pd.DataFrame,\n",
    "                      metric: SimilarityMetric,\n",
    "                      top_k: int =5):\n",
    "    results = []\n",
    "\n",
    "    # Pre-group df_cleaned by UF for faster access\n",
    "    df_by_uf = {\n",
    "        uf: group.drop_duplicates(subset=['razaosocial_cleaned', 'nome_fantasia_cleaned','cnpj',])\n",
    "        for uf, group in df_cleaned.groupby('uf')\n",
    "    }\n",
    "\n",
    "    indexes = []\n",
    "    results_dict = {}\n",
    "    for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample), desc=\"Processing\"):\n",
    "        user_input = row['user_input_cleaned']\n",
    "        razaosocial = row['razaosocial_cleaned']\n",
    "        nome_fantasia = row['nome_fantasia_cleaned']\n",
    "        not_cleaned_user_input = row['user_input']\n",
    "        true_razaosocial = row['razaosocial']\n",
    "        true_nome_fantasia = row['nome_fantasia']\n",
    "        cnpj = row['cnpj']\n",
    "        uf = row['uf']\n",
    "\n",
    "        df_uf = df_by_uf.get(uf)\n",
    "        if df_uf is None or df_uf.empty:\n",
    "            continue  # Skip if no data for that UF\n",
    "\n",
    "        # One fast match call\n",
    "        top_k_razao, top_k_nome, top_k_cnpj = TextRetrieval.find_best_matches(\n",
    "            user_input, df_uf, metric, top_k=top_k\n",
    "        )\n",
    "\n",
    "        top_1_razao = top_k_razao[0] if top_k_razao else None\n",
    "        top_1_nome = top_k_nome[0] if top_k_nome else None\n",
    "        top_1_cnpj = top_k_cnpj[0] if top_k_cnpj else None\n",
    "\n",
    "        result_row = {\n",
    "            \"user_input\": user_input,\n",
    "            \"user_input_not_cleaned\": not_cleaned_user_input,\n",
    "            \"razaosocial_not_cleaned\": true_razaosocial,\n",
    "            \"nome_fantasia_not_cleaned\": true_nome_fantasia,\n",
    "            \"razaosocial\": razaosocial,\n",
    "            \"nome_fantasia\": nome_fantasia,\n",
    "            \"cnpj\": cnpj,\n",
    "            \"uf\": uf,\n",
    "            \n",
    "            \"top_1_razaosocial_retrieved\": top_1_razao,\n",
    "            \"top_1_nomefantasia_retrieved\": top_1_nome,\n",
    "            \"top_1_cnpj_retrieved\": top_1_cnpj,\n",
    "\n",
    "            \"top_1_razaosocial_pred\": top_1_razao == true_razaosocial if top_1_razao else False,\n",
    "            \"top_1_nomefantasia_pred\": top_1_nome == true_nome_fantasia if top_1_nome else False,\n",
    "            \"top_1_cnpj_pred\": top_1_cnpj == cnpj if top_1_cnpj else False,\n",
    "\n",
    "            \"top_5_razaosocial_pred\": true_razaosocial in top_k_razao,\n",
    "            \"top_5_nomefantasia_pred\": true_nome_fantasia in top_k_nome,\n",
    "            \"top_5_cnpj_pred\": cnpj in top_k_cnpj,\n",
    "\n",
    "\n",
    "        }\n",
    "\n",
    "        # Store results in a dictionary for easy access\n",
    "        results_dict[idx] = result_row\n",
    "        results_dict[idx]['top_k_razaosocial_pred'] = top_k_razao\n",
    "        results_dict[idx]['top_k_nomefantasia_pred'] = top_k_nome\n",
    "        results_dict[idx]['top_k_cnpj_pred'] = top_k_cnpj\n",
    "        \n",
    "\n",
    "        results.append(result_row)\n",
    "        indexes.append(idx)\n",
    "\n",
    "    results_df = pd.DataFrame(results, index=indexes)\n",
    "    return results_df, results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1000/1000 [01:23<00:00, 12.05it/s]\n",
      "Processing: 100%|██████████| 1000/1000 [00:47<00:00, 20.84it/s]\n",
      "Processing: 100%|██████████| 1000/1000 [00:05<00:00, 184.00it/s]\n",
      "Processing: 100%|██████████| 1000/1000 [00:09<00:00, 108.67it/s]\n",
      "Processing: 100%|██████████| 1000/1000 [00:07<00:00, 136.90it/s]\n",
      "Processing: 100%|██████████| 1000/1000 [01:05<00:00, 15.36it/s]\n",
      "Processing: 100%|██████████| 1000/1000 [00:03<00:00, 268.29it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics = [SimilarityMetric.CER, \n",
    "           SimilarityMetric.WER,\n",
    "           SimilarityMetric.LEVENSHTEIN,\n",
    "           SimilarityMetric.JACCARD_CHARS,\n",
    "           SimilarityMetric.JACCARD_WORDS,\n",
    "           SimilarityMetric.NGRAM_JACCARD,\n",
    "           SimilarityMetric.TFIDF]\n",
    "\n",
    "sample_size = 1000\n",
    "top_k = 5\n",
    "df_sample = df_cleaned.sample(n=sample_size, random_state=42)\n",
    "accuracies = {metric.name: {} for metric in metrics}\n",
    "all_results_df = pd.DataFrame()\n",
    "for metric in metrics:\n",
    "    results_df, results_dict = evaluate_matching(df_sample, df_cleaned, metric, top_k=top_k)\n",
    "    results_df['metric'] = metric.name \n",
    "    all_results_df = pd.concat([all_results_df, results_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Rankings for top_1_razaosocial:\n",
      "1. TFIDF: 88.30%\n",
      "2. NGRAM_JACCARD: 82.00%\n",
      "3. JACCARD_WORDS: 72.70%\n",
      "4. WER: 64.60%\n",
      "5. LEVENSHTEIN: 60.60%\n",
      "6. CER: 59.70%\n",
      "7. JACCARD_CHARS: 45.00%\n",
      "====================================================================================================\n",
      "Rankings for top_1_nomefantasia:\n",
      "1. TFIDF: 71.70%\n",
      "2. NGRAM_JACCARD: 64.30%\n",
      "3. JACCARD_WORDS: 58.00%\n",
      "4. WER: 48.50%\n",
      "5. LEVENSHTEIN: 45.50%\n",
      "6. CER: 45.00%\n",
      "7. JACCARD_CHARS: 34.80%\n",
      "====================================================================================================\n",
      "Rankings for top_1_cnpj:\n",
      "1. TFIDF: 35.60%\n",
      "2. NGRAM_JACCARD: 8.80%\n",
      "3. JACCARD_WORDS: 8.00%\n",
      "4. CER: 5.70%\n",
      "5. LEVENSHTEIN: 5.70%\n",
      "6. JACCARD_CHARS: 5.20%\n",
      "7. WER: 3.70%\n",
      "====================================================================================================\n",
      "Rankings for top_5_razaosocial:\n",
      "1. TFIDF: 95.90%\n",
      "2. NGRAM_JACCARD: 90.70%\n",
      "3. JACCARD_WORDS: 82.10%\n",
      "4. WER: 74.70%\n",
      "5. LEVENSHTEIN: 73.10%\n",
      "6. CER: 70.90%\n",
      "7. JACCARD_CHARS: 58.10%\n",
      "====================================================================================================\n",
      "Rankings for top_5_nomefantasia:\n",
      "1. TFIDF: 85.90%\n",
      "2. NGRAM_JACCARD: 79.30%\n",
      "3. JACCARD_WORDS: 71.00%\n",
      "4. WER: 62.00%\n",
      "5. LEVENSHTEIN: 61.90%\n",
      "6. CER: 59.30%\n",
      "7. JACCARD_CHARS: 48.90%\n",
      "====================================================================================================\n",
      "Rankings for top_5_cnpj:\n",
      "1. TFIDF: 55.50%\n",
      "2. NGRAM_JACCARD: 45.70%\n",
      "3. LEVENSHTEIN: 35.70%\n",
      "4. JACCARD_WORDS: 34.00%\n",
      "5. CER: 33.00%\n",
      "6. WER: 27.80%\n",
      "7. JACCARD_CHARS: 27.60%\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "accuracies = {}\n",
    "for metric in metrics:\n",
    "    metric_name = metric.name\n",
    "    metric_df = all_results_df[all_results_df['metric'] == metric_name]\n",
    "    accuracies[metric_name] = {\n",
    "        'top_1_razaosocial': metric_df['top_1_razaosocial_pred'].mean(),\n",
    "        'top_1_nomefantasia': metric_df['top_1_nomefantasia_pred'].mean(),\n",
    "        'top_1_cnpj': metric_df['top_1_cnpj_pred'].mean(),\n",
    "        'top_5_razaosocial': metric_df['top_5_razaosocial_pred'].mean(),\n",
    "        'top_5_nomefantasia': metric_df['top_5_nomefantasia_pred'].mean(),\n",
    "        'top_5_cnpj': metric_df['top_5_cnpj_pred'].mean()\n",
    "    }\n",
    "\n",
    "# Determine the best metric for each case and print rankings\n",
    "cases = ['top_1_razaosocial', 'top_1_nomefantasia', 'top_1_cnpj', 'top_5_razaosocial', 'top_5_nomefantasia', 'top_5_cnpj']\n",
    "print(\"=\" * 100)\n",
    "for case in cases:\n",
    "    sorted_metrics = sorted(accuracies.items(), key=lambda x: x[1][case], reverse=True)\n",
    "    print(f\"Rankings for {case}:\")\n",
    "    for rank, (metric_name, _) in enumerate(sorted_metrics, start=1):\n",
    "        accuracy = accuracies[metric_name][case] * 100\n",
    "        print(f\"{rank}. {metric_name}: {accuracy:.2f}%\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observado acima, a métrica de TF-IDF com a similaridade do cosseno foi significativamente melhor em todos os casos. Assim, iremos utilizar essa métrica para calcular os resultados em todo o conjunto de dados além das 1000 amostras já utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 255065/255065 [13:07<00:00, 323.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "\n",
      "Resultados da Avaliação para a métrica: TFIDF\n",
      "Tamanho do DataFrame de Resultados: (255065, 20)\n",
      "Número de Linhas com Predições Corretas (Top 1 Razão Social): 222172\n",
      "Número de Linhas com Predições Corretas (Top 1 Nome Fantasia): 179033\n",
      "Número de Linhas com Predições Corretas (Top 1 CNPJ): 88325\n",
      "Número de Linhas com Predições Corretas (Top 5 Razão Social): 240951\n",
      "Número de Linhas com Predições Corretas (Top 5 Nome Fantasia): 215641\n",
      "Número de Linhas com Predições Corretas (Top 5 CNPJ): 140089\n",
      "Acuracias:\n",
      "Top 1 Razão Social: 87.10%\n",
      "Top 1 Nome Fantasia: 70.19%\n",
      "Top 1 CNPJ: 34.63%\n",
      "Top 5 Razão Social: 94.47%\n",
      "Top 5 Nome Fantasia: 84.54%\n",
      "Top 5 CNPJ: 54.92%\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "metric = SimilarityMetric.TFIDF\n",
    "results_df, results_dict = evaluate_matching(df_cleaned, df_cleaned, metric, top_k=top_k)\n",
    "print(\"=\"* 100)\n",
    "print(f\"\\nResultados da Avaliação para a métrica: {metric.name}\"\n",
    "      f\"\\nTamanho do DataFrame de Resultados: {results_df.shape}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 Razão Social): {results_df['top_1_razaosocial_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 Nome Fantasia): {results_df['top_1_nomefantasia_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 CNPJ): {results_df['top_1_cnpj_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 Razão Social): {results_df['top_5_razaosocial_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 Nome Fantasia): {results_df['top_5_nomefantasia_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 CNPJ): {results_df['top_5_cnpj_pred'].sum()}\"\n",
    "      f\"\\nAcuracias:\\n\"\n",
    "      f\"Top 1 Razão Social: {results_df['top_1_razaosocial_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 1 Nome Fantasia: {results_df['top_1_nomefantasia_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 1 CNPJ: {results_df['top_1_cnpj_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 Razão Social: {results_df['top_5_razaosocial_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 Nome Fantasia: {results_df['top_5_nomefantasia_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 CNPJ: {results_df['top_5_cnpj_pred'].mean() * 100:.2f}%\")\n",
    "print(\"=\"* 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"tf-idf-results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Análise dos Resultados\n",
    "\n",
    "Como observado acima, o `TextRetriever` implementado com o `TF-IDF` e `Cosine Similarity` apresentou os melhores resultados. Por outro lado, mesmo o TF-IDF nao obteve um resultado satisfatório para o `CNPJ` retornado no top 1 ou top 5, embora os resultados para a `razaosocial` e `nome_fantasia` nao tenham sido ruins.\n",
    "\n",
    "Vamos observar como os erros de CNPJ no top 5 se distribuem em relacao aos erros e acertos de `razaosocial` e `nome_fantasia`.\n",
    "\n",
    "Uma hipótese para o poeque isso acontece é que dentro de um mesmo estado/`uf` um mesmo par `razaosocial` e `nome_fantasia` pode ter diferentes `CNPJ`s, o que torna a tarefa de recuperação de `CNPJ` mais complexa mesmo quando se obtem o par `razaosocial` e `nome_fantasia` corretos. Para verificar se isso acontece, observemos como os erros de CNPJ se distribuem quando há acertos e/ou erros para a `razaosocial` e `nome_fantasia`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribuição dos Erros de CNPJ:\n",
      "\n",
      "Erro no Top 5 Razão Social e Nome Fantasia: 11.33%\n",
      "Erro no Top 5 Razão Social e acerto no Top 5 Nome Fantasia: 0.94%\n",
      "Acerto no Top 5 Razão Social e erro no Top 5 Nome Fantasia: 22.96%\n",
      "Acerto no Top 5 Razão Social e Nome Fantasia: 64.77%\n"
     ]
    }
   ],
   "source": [
    "# Checking how the CNPJ errors are distributed in relation to the other errors\n",
    "\n",
    "# Erro no Top 5 Razão Social e erro no Top 5 Nome Fantasia\n",
    "erro_top5_razao_nome = results_df[\n",
    "    (results_df['top_5_razaosocial_pred'] == False) & \n",
    "    (results_df['top_5_nomefantasia_pred'] == False) &\n",
    "    (results_df['top_5_cnpj_pred'] == False)\n",
    "]\n",
    "\n",
    "# Erro no Top 5 Razão Social e acerto no Top 5 Nome Fantasia\n",
    "erro_top5_razao_acerto_nome = results_df[\n",
    "    (results_df['top_5_razaosocial_pred'] == False) & \n",
    "    (results_df['top_5_nomefantasia_pred'] == True) &\n",
    "    (results_df['top_5_cnpj_pred'] == False)\n",
    "]\n",
    "# Acerto no Top 5 Razão Social e erro no Top 5 Nome Fantasia\n",
    "erro_top5_acerto_razao_nome = results_df[\n",
    "    (results_df['top_5_razaosocial_pred'] == True) & \n",
    "    (results_df['top_5_nomefantasia_pred'] == False) &\n",
    "    (results_df['top_5_cnpj_pred'] == False)\n",
    "]\n",
    "\n",
    "# Acerto no Top 5 Razão Social e Nome Fantasia\n",
    "acerto_top5_razao_nome = results_df[\n",
    "    (results_df['top_5_razaosocial_pred'] == True) & \n",
    "    (results_df['top_5_nomefantasia_pred'] == True) &\n",
    "    (results_df['top_5_cnpj_pred'] == False)\n",
    "]\n",
    "\n",
    "total_cnpj_errors = results_df[\n",
    "    (results_df['top_5_cnpj_pred'] == False)\n",
    "]\n",
    "print(\"\\nDistribuição dos Erros de CNPJ:\")\n",
    "print(f\"\\nErro no Top 5 Razão Social e Nome Fantasia: {len(erro_top5_razao_nome)/len(total_cnpj_errors) * 100:.2f}%\")\n",
    "print(f\"Erro no Top 5 Razão Social e acerto no Top 5 Nome Fantasia: {len(erro_top5_razao_acerto_nome)/len(total_cnpj_errors) * 100:.2f}%\")\n",
    "print(f\"Acerto no Top 5 Razão Social e erro no Top 5 Nome Fantasia: {len(erro_top5_acerto_razao_nome)/len(total_cnpj_errors) * 100:.2f}%\")\n",
    "print(f\"Acerto no Top 5 Razão Social e Nome Fantasia: {len(acerto_top5_razao_nome)/len(total_cnpj_errors) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como verificado acima a maioria dos erros ocorre quando  houve acerto na `razaosocial` e/ou `nome_fantasia`, sendo que `64.77%` dos erros de CNPJ no top 5 ocorre em casos em que houve acerto de ambos `razaosocial` e `nome_fantasia`, mas o CNPJ retornado não é o correto. \n",
    "\n",
    "Isso ocorre provavelmente porque no conjunto de dados, em um mesmo estado (`uf`), há mais de uma empresa com os mesmos `razaosocial` e `nome_fantasia`. Verifiquemos se isso é verdade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of pairs with multiple CNPJs per UF:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairs_with_multiple_cnpjs</th>\n",
       "      <th>percentage_records_in_multi_cnpj</th>\n",
       "      <th>records_in_multi_cnpj</th>\n",
       "      <th>total_records</th>\n",
       "      <th>avg_cnpjs_per_problematic_pair</th>\n",
       "      <th>max_cnpjs_per_pair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uf</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SP</th>\n",
       "      <td>351</td>\n",
       "      <td>48.19</td>\n",
       "      <td>38911</td>\n",
       "      <td>80737</td>\n",
       "      <td>9.44</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>187</td>\n",
       "      <td>72.33</td>\n",
       "      <td>25653</td>\n",
       "      <td>35467</td>\n",
       "      <td>11.27</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR</th>\n",
       "      <td>166</td>\n",
       "      <td>67.79</td>\n",
       "      <td>18917</td>\n",
       "      <td>27904</td>\n",
       "      <td>9.15</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>112</td>\n",
       "      <td>66.47</td>\n",
       "      <td>11576</td>\n",
       "      <td>17416</td>\n",
       "      <td>8.45</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>86</td>\n",
       "      <td>53.09</td>\n",
       "      <td>8969</td>\n",
       "      <td>16894</td>\n",
       "      <td>7.95</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RJ</th>\n",
       "      <td>62</td>\n",
       "      <td>46.82</td>\n",
       "      <td>5471</td>\n",
       "      <td>11684</td>\n",
       "      <td>7.58</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>53</td>\n",
       "      <td>46.55</td>\n",
       "      <td>3884</td>\n",
       "      <td>8343</td>\n",
       "      <td>5.92</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO</th>\n",
       "      <td>46</td>\n",
       "      <td>40.55</td>\n",
       "      <td>2644</td>\n",
       "      <td>6520</td>\n",
       "      <td>4.72</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MS</th>\n",
       "      <td>36</td>\n",
       "      <td>57.54</td>\n",
       "      <td>2449</td>\n",
       "      <td>4256</td>\n",
       "      <td>5.22</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CE</th>\n",
       "      <td>31</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2583</td>\n",
       "      <td>5539</td>\n",
       "      <td>6.52</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>29</td>\n",
       "      <td>35.97</td>\n",
       "      <td>1767</td>\n",
       "      <td>4913</td>\n",
       "      <td>5.14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT</th>\n",
       "      <td>27</td>\n",
       "      <td>48.17</td>\n",
       "      <td>2481</td>\n",
       "      <td>5151</td>\n",
       "      <td>6.56</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>26</td>\n",
       "      <td>46.72</td>\n",
       "      <td>1603</td>\n",
       "      <td>3431</td>\n",
       "      <td>5.19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF</th>\n",
       "      <td>25</td>\n",
       "      <td>30.23</td>\n",
       "      <td>916</td>\n",
       "      <td>3030</td>\n",
       "      <td>3.16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>18</td>\n",
       "      <td>45.80</td>\n",
       "      <td>2215</td>\n",
       "      <td>4836</td>\n",
       "      <td>9.06</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PB</th>\n",
       "      <td>16</td>\n",
       "      <td>36.69</td>\n",
       "      <td>957</td>\n",
       "      <td>2608</td>\n",
       "      <td>4.81</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>16</td>\n",
       "      <td>40.51</td>\n",
       "      <td>1138</td>\n",
       "      <td>2809</td>\n",
       "      <td>5.31</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RN</th>\n",
       "      <td>15</td>\n",
       "      <td>40.09</td>\n",
       "      <td>793</td>\n",
       "      <td>1978</td>\n",
       "      <td>3.87</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PI</th>\n",
       "      <td>11</td>\n",
       "      <td>47.39</td>\n",
       "      <td>871</td>\n",
       "      <td>1838</td>\n",
       "      <td>5.73</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AM</th>\n",
       "      <td>11</td>\n",
       "      <td>26.78</td>\n",
       "      <td>565</td>\n",
       "      <td>2110</td>\n",
       "      <td>3.91</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>9</td>\n",
       "      <td>43.85</td>\n",
       "      <td>691</td>\n",
       "      <td>1576</td>\n",
       "      <td>5.22</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>8</td>\n",
       "      <td>37.62</td>\n",
       "      <td>427</td>\n",
       "      <td>1135</td>\n",
       "      <td>4.38</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TO</th>\n",
       "      <td>8</td>\n",
       "      <td>28.05</td>\n",
       "      <td>384</td>\n",
       "      <td>1369</td>\n",
       "      <td>4.12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>6</td>\n",
       "      <td>35.28</td>\n",
       "      <td>641</td>\n",
       "      <td>1817</td>\n",
       "      <td>7.33</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>4</td>\n",
       "      <td>52.44</td>\n",
       "      <td>366</td>\n",
       "      <td>698</td>\n",
       "      <td>6.25</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>2</td>\n",
       "      <td>22.25</td>\n",
       "      <td>83</td>\n",
       "      <td>373</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RR</th>\n",
       "      <td>1</td>\n",
       "      <td>28.45</td>\n",
       "      <td>138</td>\n",
       "      <td>485</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX</th>\n",
       "      <td>1</td>\n",
       "      <td>3.43</td>\n",
       "      <td>19</td>\n",
       "      <td>554</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pairs_with_multiple_cnpjs  percentage_records_in_multi_cnpj  \\\n",
       "uf                                                                \n",
       "SP                        351                             48.19   \n",
       "RS                        187                             72.33   \n",
       "PR                        166                             67.79   \n",
       "SC                        112                             66.47   \n",
       "MG                         86                             53.09   \n",
       "RJ                         62                             46.82   \n",
       "BA                         53                             46.55   \n",
       "GO                         46                             40.55   \n",
       "MS                         36                             57.54   \n",
       "CE                         31                             46.63   \n",
       "PE                         29                             35.97   \n",
       "MT                         27                             48.17   \n",
       "MA                         26                             46.72   \n",
       "DF                         25                             30.23   \n",
       "PA                         18                             45.80   \n",
       "PB                         16                             36.69   \n",
       "ES                         16                             40.51   \n",
       "RN                         15                             40.09   \n",
       "PI                         11                             47.39   \n",
       "AM                         11                             26.78   \n",
       "RO                          9                             43.85   \n",
       "SE                          8                             37.62   \n",
       "TO                          8                             28.05   \n",
       "AL                          6                             35.28   \n",
       "AC                          4                             52.44   \n",
       "AP                          2                             22.25   \n",
       "RR                          1                             28.45   \n",
       "EX                          1                              3.43   \n",
       "\n",
       "    records_in_multi_cnpj  total_records  avg_cnpjs_per_problematic_pair  \\\n",
       "uf                                                                         \n",
       "SP                  38911          80737                            9.44   \n",
       "RS                  25653          35467                           11.27   \n",
       "PR                  18917          27904                            9.15   \n",
       "SC                  11576          17416                            8.45   \n",
       "MG                   8969          16894                            7.95   \n",
       "RJ                   5471          11684                            7.58   \n",
       "BA                   3884           8343                            5.92   \n",
       "GO                   2644           6520                            4.72   \n",
       "MS                   2449           4256                            5.22   \n",
       "CE                   2583           5539                            6.52   \n",
       "PE                   1767           4913                            5.14   \n",
       "MT                   2481           5151                            6.56   \n",
       "MA                   1603           3431                            5.19   \n",
       "DF                    916           3030                            3.16   \n",
       "PA                   2215           4836                            9.06   \n",
       "PB                    957           2608                            4.81   \n",
       "ES                   1138           2809                            5.31   \n",
       "RN                    793           1978                            3.87   \n",
       "PI                    871           1838                            5.73   \n",
       "AM                    565           2110                            3.91   \n",
       "RO                    691           1576                            5.22   \n",
       "SE                    427           1135                            4.38   \n",
       "TO                    384           1369                            4.12   \n",
       "AL                    641           1817                            7.33   \n",
       "AC                    366            698                            6.25   \n",
       "AP                     83            373                            3.00   \n",
       "RR                    138            485                            9.00   \n",
       "EX                     19            554                            2.00   \n",
       "\n",
       "    max_cnpjs_per_pair  \n",
       "uf                      \n",
       "SP                 417  \n",
       "RS                 275  \n",
       "PR                 152  \n",
       "SC                 105  \n",
       "MG                 301  \n",
       "RJ                  79  \n",
       "BA                  67  \n",
       "GO                  39  \n",
       "MS                  31  \n",
       "CE                  48  \n",
       "PE                  20  \n",
       "MT                  28  \n",
       "MA                  19  \n",
       "DF                   9  \n",
       "PA                  92  \n",
       "PB                  15  \n",
       "ES                  39  \n",
       "RN                  11  \n",
       "PI                  20  \n",
       "AM                  20  \n",
       "RO                  17  \n",
       "SE                  12  \n",
       "TO                  13  \n",
       "AL                  26  \n",
       "AC                  11  \n",
       "AP                   4  \n",
       "RR                   9  \n",
       "EX                   2  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick analysis with distribution of CNPJ counts\n",
    "cnpj_counts_per_pair = df.groupby(['uf', 'razaosocial', 'nome_fantasia'])['cnpj'].nunique()\n",
    "\n",
    "# Get total records per UF\n",
    "total_records_per_uf = df.groupby('uf').size()\n",
    "\n",
    "# Count pairs with multiple CNPJs per UF\n",
    "multiple_cnpjs_summary = (\n",
    "    cnpj_counts_per_pair[cnpj_counts_per_pair > 1]\n",
    "    .reset_index()\n",
    "    .groupby('uf')\n",
    "    .agg({\n",
    "        'cnpj': ['count', 'mean', 'max']\n",
    "    })\n",
    ")\n",
    "multiple_cnpjs_summary.columns = ['pairs_with_multiple_cnpjs', 'avg_cnpjs_per_problematic_pair', 'max_cnpjs_per_pair']\n",
    "\n",
    "# Add total records per UF\n",
    "multiple_cnpjs_summary['total_records'] = total_records_per_uf\n",
    "\n",
    "# Calculate percentage of records that belong to pairs with multiple CNPJs\n",
    "# First, get the number of records for each pair with multiple CNPJs\n",
    "records_in_multi_cnpj = (\n",
    "    df[df.groupby(['uf', 'razaosocial', 'nome_fantasia'])['cnpj'].transform('nunique') > 1]\n",
    "    .groupby('uf')\n",
    "    .size()\n",
    ")\n",
    "\n",
    "# Add this to our summary\n",
    "multiple_cnpjs_summary['records_in_multi_cnpj'] = records_in_multi_cnpj.reindex(multiple_cnpjs_summary.index, fill_value=0)\n",
    "\n",
    "# Calculate percentage\n",
    "multiple_cnpjs_summary['percentage_records_in_multi_cnpj'] = (\n",
    "    multiple_cnpjs_summary['records_in_multi_cnpj'] / \n",
    "    multiple_cnpjs_summary['total_records'] * 100\n",
    ").round(2)\n",
    "\n",
    "# Reorder columns for better readability\n",
    "multiple_cnpjs_summary = multiple_cnpjs_summary[[\n",
    "    'pairs_with_multiple_cnpjs', \n",
    "    'percentage_records_in_multi_cnpj',\n",
    "    'records_in_multi_cnpj',\n",
    "    'total_records',\n",
    "    'avg_cnpjs_per_problematic_pair', \n",
    "    'max_cnpjs_per_pair'\n",
    "]].round(2).sort_values('pairs_with_multiple_cnpjs', ascending=False)\n",
    "\n",
    "print(\"Summary of pairs with multiple CNPJs per UF:\")\n",
    "multiple_cnpjs_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tabela acima revela que em todos os `uf` presentes no conjunto de dados, há um número significativo de empresas com o mesmo `razaosocial` e `nome_fantasia`, mas com `CNPJ`s diferentes. \n",
    "\n",
    "A tarefa de recuperação de `CNPJ` de uma empresa em determinado estado (`uf`) necessita, entao, de mais informacoes do qu a `razaosocial` e `nome_fantasia` da empresa buscada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Criacao de Retriever Utilizando Sentence Transformers\n",
    "\n",
    "Como a acurácia do retriever baseado em métodos clássicos não foi satisfatória, vamos implementar um retriever utilizando embeddings de sentenças. Serao gerados embeddings para as colunas `razaosocial_cleaned` e `nome_fantasia_cleaned`. Tais embeddings serão utilizados para calcular a similaridade entre o `user_input_cleaned` e as colunas mencionadas. A métrica de similaridade utilizada será a similaridade cosseno, que é uma métrica comum para medir a similaridade entre vetores de alta dimensão e é a mesma utilizada anteriormente para calcular a similaridade entre os vetores TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import Counter\n",
    "\n",
    "class SemanticRetrieval:\n",
    "    def __init__(self, df: pd.DataFrame, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.df = df.copy()\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.index = None\n",
    "        self.embeddings = None\n",
    "        self.id_map = None  # maps index -> df index\n",
    "        self._prepare_index()\n",
    "\n",
    "    def _prepare_index(self):\n",
    "        # Combine cleaned fields for semantic search\n",
    "        self.df['razaosocial_cleaned'] = self.df['razaosocial'].apply(comprehensive_text_cleaning)\n",
    "        self.df['nome_fantasia_cleaned'] = self.df['nome_fantasia'].apply(comprehensive_text_cleaning)\n",
    "        self.df['combined'] = (\n",
    "            self.df['razaosocial_cleaned'].fillna('') + ' ' +\n",
    "            self.df['nome_fantasia_cleaned'].fillna('')\n",
    "        )\n",
    "\n",
    "        # Compute embeddings\n",
    "        self.embeddings = self.model.encode(self.df['combined'].tolist(), show_progress_bar=True)\n",
    "        self.embeddings = np.array(self.embeddings).astype('float32')\n",
    "\n",
    "        # Create FAISS index\n",
    "        dimension = self.embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(dimension)\n",
    "        self.index.add(self.embeddings)\n",
    "\n",
    "        # Store mapping from index -> dataframe row\n",
    "        self.id_map = self.df.index.to_numpy()\n",
    "\n",
    "    def search(self, user_input: str, top_k: int = 5, uf: str = None) -> dict:\n",
    "        user_embedding = self.model.encode([user_input]).astype('float32')\n",
    "        distances, indices = self.index.search(user_embedding, top_k)\n",
    "\n",
    "        matched_rows = self.df.iloc[self.id_map[indices[0]]].copy()\n",
    "\n",
    "        if uf:\n",
    "            matched_rows = matched_rows[matched_rows['uf'] == uf]\n",
    "\n",
    "        cnpjs = matched_rows['cnpj'].dropna().tolist()\n",
    "        most_common_cnpjs = [cnpj for cnpj, _ in Counter(cnpjs).most_common(top_k)]\n",
    "\n",
    "        return {\n",
    "            'razaosocial': matched_rows['razaosocial'].tolist(),\n",
    "            'nome_fantasia': matched_rows['nome_fantasia'].tolist(),\n",
    "            'cnpjs': most_common_cnpjs,\n",
    "            'distances': distances[0].tolist()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_matching_fast_semantic(df_sample, df_cleaned, top_k=5):\n",
    "    results = []\n",
    "    indexes = []\n",
    "    results_dict = {}\n",
    "\n",
    "    # Group df_cleaned by UF and prebuild a SemanticRetrieval for each\n",
    "    retrievers_by_uf = {}\n",
    "    for uf, group in df_cleaned.groupby('uf'):\n",
    "        group = group.drop_duplicates(subset=['razaosocial_cleaned', 'nome_fantasia_cleaned', 'cnpj'])\n",
    "        group = group.reset_index(drop=False) \n",
    "        retrievers_by_uf[uf] = SemanticRetrieval(group)\n",
    "\n",
    "    for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample), desc=\"Semantic Matching\"):\n",
    "        user_input = row['user_input_cleaned']\n",
    "        razaosocial = row['razaosocial_cleaned']\n",
    "        nome_fantasia = row['nome_fantasia_cleaned']\n",
    "        not_cleaned_user_input = row['user_input']\n",
    "        not_cleaned_razaosocial = row['razaosocial']\n",
    "        not_cleaned_nome_fantasia = row['nome_fantasia']\n",
    "        cnpj = row['cnpj']\n",
    "        uf = row['uf']\n",
    "\n",
    "        retriever = retrievers_by_uf.get(uf)\n",
    "        if retriever is None:\n",
    "            continue  # Skip if no retriever for that UF\n",
    "\n",
    "        result = retriever.search(user_input, top_k=top_k)\n",
    "\n",
    "        top_k_razao = result['razaosocial']\n",
    "        top_k_nome = result['nome_fantasia']\n",
    "        top_k_cnpj = result['cnpjs']\n",
    "\n",
    "        top_1_razao = top_k_razao[0] if top_k_razao else None\n",
    "        top_1_nome = top_k_nome[0] if top_k_nome else None\n",
    "        top_1_cnpj = top_k_cnpj[0] if top_k_cnpj else None\n",
    "\n",
    "        result_row = {\n",
    "            \"user_input\": user_input,\n",
    "            \"user_input_not_cleaned\": not_cleaned_user_input,\n",
    "            \"razaosocial_not_cleaned\": not_cleaned_razaosocial,\n",
    "            \"nome_fantasia_not_cleaned\": not_cleaned_nome_fantasia,\n",
    "            \"razaosocial\": razaosocial,\n",
    "            \"nome_fantasia\": nome_fantasia,\n",
    "            \"cnpj\": cnpj,\n",
    "            \"uf\": uf,\n",
    "            \n",
    "            \"top_1_razaosocial_retrieved\": top_1_razao,\n",
    "            \"top_1_nomefantasia_retrieved\": top_1_nome,\n",
    "            \"top_1_cnpj_retrieved\": top_1_cnpj,\n",
    "\n",
    "            \"top_1_razaosocial_pred\": top_1_razao == not_cleaned_razaosocial if top_1_razao else False,\n",
    "            \"top_1_nomefantasia_pred\": top_1_nome == not_cleaned_nome_fantasia if top_1_nome else False,\n",
    "            \"top_1_cnpj_pred\": top_1_cnpj == cnpj if top_1_cnpj else False,\n",
    "\n",
    "            \"top_5_razaosocial_pred\": not_cleaned_razaosocial in top_k_razao,\n",
    "            \"top_5_nomefantasia_pred\": not_cleaned_nome_fantasia in top_k_nome,\n",
    "            \"top_5_cnpj_pred\": cnpj in top_k_cnpj,\n",
    "        }\n",
    "\n",
    "        results_dict[idx] = result_row\n",
    "        results_dict[idx]['top_k_razaosocial_pred'] = top_k_razao\n",
    "        results_dict[idx]['top_k_nomefantasia_pred'] = top_k_nome\n",
    "        results_dict[idx]['top_k_cnpj_pred'] = top_k_cnpj\n",
    "\n",
    "        results.append(result_row)\n",
    "        indexes.append(idx)\n",
    "\n",
    "    results_df = pd.DataFrame(results, index=indexes)\n",
    "    return results_df, results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]\n",
      "Batches: 100%|██████████| 5/5 [00:00<00:00,  5.39it/s]\n",
      "Batches: 100%|██████████| 6/6 [00:04<00:00,  1.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 18.27it/s]\n",
      "Batches: 100%|██████████| 23/23 [00:01<00:00, 13.21it/s]\n",
      "Batches: 100%|██████████| 15/15 [00:00<00:00, 15.94it/s]\n",
      "Batches: 100%|██████████| 9/9 [00:00<00:00, 10.57it/s]\n",
      "Batches: 100%|██████████| 8/8 [00:00<00:00, 10.86it/s]\n",
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  6.24it/s]\n",
      "Batches: 100%|██████████| 18/18 [00:01<00:00, 15.80it/s]\n",
      "Batches: 100%|██████████| 10/10 [00:01<00:00,  6.08it/s]\n",
      "Batches: 100%|██████████| 44/44 [00:02<00:00, 21.38it/s]\n",
      "Batches: 100%|██████████| 11/11 [00:00<00:00, 14.77it/s]\n",
      "Batches: 100%|██████████| 13/13 [00:01<00:00, 12.38it/s]\n",
      "Batches: 100%|██████████| 13/13 [00:00<00:00, 13.17it/s]\n",
      "Batches: 100%|██████████| 8/8 [00:01<00:00,  5.63it/s]\n",
      "Batches: 100%|██████████| 14/14 [00:01<00:00, 12.54it/s]\n",
      "Batches: 100%|██████████| 5/5 [00:00<00:00, 12.69it/s]\n",
      "Batches: 100%|██████████| 72/72 [00:02<00:00, 29.30it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:01<00:00, 24.35it/s]\n",
      "Batches: 100%|██████████| 6/6 [00:00<00:00, 12.79it/s]\n",
      "Batches: 100%|██████████| 4/4 [00:00<00:00,  8.96it/s]\n",
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  4.26it/s]\n",
      "Batches: 100%|██████████| 93/93 [00:03<00:00, 23.87it/s]\n",
      "Batches: 100%|██████████| 46/46 [00:01<00:00, 30.45it/s]\n",
      "Batches: 100%|██████████| 4/4 [00:00<00:00,  8.74it/s]\n",
      "Batches: 100%|██████████| 215/215 [00:04<00:00, 46.38it/s]\n",
      "Batches: 100%|██████████| 4/4 [00:00<00:00,  9.68it/s]\n",
      "Semantic Matching: 100%|██████████| 1000/1000 [00:14<00:00, 68.41it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_size = 1000\n",
    "top_k = 5\n",
    "if sample_size:\n",
    "    df_sample = df_cleaned.sample(n=sample_size, random_state=42)\n",
    "else:\n",
    "    df_sample = df_cleaned\n",
    "results_df, results_dict = evaluate_matching_fast_semantic(df_sample, df_cleaned, top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados da Avaliação:\n",
      "Tamanho do DataFrame de Resultados: (1000, 20)\n",
      "Número de Linhas com Predições Corretas (Top 1 Razão Social): 450\n",
      "Número de Linhas com Predições Corretas (Top 1 Nome Fantasia): 331\n",
      "Número de Linhas com Predições Corretas (Top 1 CNPJ): 158\n",
      "Número de Linhas com Predições Corretas (Top 5 Razão Social): 532\n",
      "Número de Linhas com Predições Corretas (Top 5 Nome Fantasia): 446\n",
      "Número de Linhas com Predições Corretas (Top 5 CNPJ): 281\n",
      "Acuracias:\n",
      "Top 1 Razão Social: 45.00%\n",
      "Top 1 Nome Fantasia: 33.10%\n",
      "Top 1 CNPJ: 15.80%\n",
      "Top 5 Razão Social: 53.20%\n",
      "Top 5 Nome Fantasia: 44.60%\n",
      "Top 5 CNPJ: 28.10%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResultados da Avaliação:\"\n",
    "      f\"\\nTamanho do DataFrame de Resultados: {results_df.shape}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 Razão Social): {results_df['top_1_razaosocial_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 Nome Fantasia): {results_df['top_1_nomefantasia_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 1 CNPJ): {results_df['top_1_cnpj_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 Razão Social): {results_df['top_5_razaosocial_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 Nome Fantasia): {results_df['top_5_nomefantasia_pred'].sum()}\"\n",
    "      f\"\\nNúmero de Linhas com Predições Corretas (Top 5 CNPJ): {results_df['top_5_cnpj_pred'].sum()}\"\n",
    "      f\"\\nAcuracias:\\n\"\n",
    "      f\"Top 1 Razão Social: {results_df['top_1_razaosocial_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 1 Nome Fantasia: {results_df['top_1_nomefantasia_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 1 CNPJ: {results_df['top_1_cnpj_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 Razão Social: {results_df['top_5_razaosocial_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 Nome Fantasia: {results_df['top_5_nomefantasia_pred'].mean() * 100:.2f}%\"\n",
    "      f\"\\nTop 5 CNPJ: {results_df['top_5_cnpj_pred'].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>user_input_not_cleaned</th>\n",
       "      <th>razaosocial_not_cleaned</th>\n",
       "      <th>nome_fantasia_not_cleaned</th>\n",
       "      <th>razaosocial</th>\n",
       "      <th>nome_fantasia</th>\n",
       "      <th>cnpj</th>\n",
       "      <th>uf</th>\n",
       "      <th>top_1_razaosocial_retrieved</th>\n",
       "      <th>top_1_nomefantasia_retrieved</th>\n",
       "      <th>top_1_cnpj_retrieved</th>\n",
       "      <th>top_1_razaosocial_pred</th>\n",
       "      <th>top_1_nomefantasia_pred</th>\n",
       "      <th>top_1_cnpj_pred</th>\n",
       "      <th>top_5_razaosocial_pred</th>\n",
       "      <th>top_5_nomefantasia_pred</th>\n",
       "      <th>top_5_cnpj_pred</th>\n",
       "      <th>top_k_razaosocial_pred</th>\n",
       "      <th>top_k_nomefantasia_pred</th>\n",
       "      <th>top_k_cnpj_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181538</th>\n",
       "      <td>deus franca</td>\n",
       "      <td>DEUS FRANCA</td>\n",
       "      <td>IGREJA EVANGELICA ASSEMBLEIA DE DEUS EM FRANCA-SP</td>\n",
       "      <td>ASSEMBLEIA DE DEUS</td>\n",
       "      <td>igreja evangelica assembleia deus franca sp</td>\n",
       "      <td>assembleia deus</td>\n",
       "      <td>47041223002376</td>\n",
       "      <td>SP</td>\n",
       "      <td>NOVA FRANCA PARTICIPACOES LTDA</td>\n",
       "      <td>NOVA FRANCA IMOBILIARIA</td>\n",
       "      <td>47998745000155</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[NOVA FRANCA PARTICIPACOES LTDA, CONFECCOES AL...</td>\n",
       "      <td>[NOVA FRANCA IMOBILIARIA, CONFECCOES ALVARO, E...</td>\n",
       "      <td>[47998745000155, 43306715000180, 6070119031004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>sao joao faramsia</td>\n",
       "      <td>SAO JOAO FARAMSIA</td>\n",
       "      <td>COMERCIO DE MEDICAMENTOS BRAIR LTDA</td>\n",
       "      <td>SAO JOAO FARMACIAS</td>\n",
       "      <td>medicamentos brair</td>\n",
       "      <td>sao joao farmacias</td>\n",
       "      <td>88212113030351</td>\n",
       "      <td>RS</td>\n",
       "      <td>ASSOCIACAO BRASILEIRA D'A IGREJA DE JESUS CRIS...</td>\n",
       "      <td>SAO FRANCISCO DE PAULA</td>\n",
       "      <td>61012019158366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[ASSOCIACAO BRASILEIRA D'A IGREJA DE JESUS CRI...</td>\n",
       "      <td>[SAO FRANCISCO DE PAULA, SUPERMERCADO CARANGOL...</td>\n",
       "      <td>[61012019158366, 94739992000117, 6101201910940...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167507</th>\n",
       "      <td>bras i</td>\n",
       "      <td>BRAS DE A I</td>\n",
       "      <td>ASSOCIACAO BRASILEIRA D'A IGREJA DE JESUS CRIS...</td>\n",
       "      <td>ASSOC BRAS DE A I DE JESUS CRISTO DOS SANTOS D...</td>\n",
       "      <td>associacao brasileira d a igreja jesus cristo ...</td>\n",
       "      <td>assoc bras i jesus cristo santos u dias</td>\n",
       "      <td>61012019060986</td>\n",
       "      <td>BA</td>\n",
       "      <td>OTICAS FAM LTDA</td>\n",
       "      <td>OTICAS FAM</td>\n",
       "      <td>53796458000165</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[OTICAS FAM LTDA, BRASKEM S.A, RI HAPPY BRINQU...</td>\n",
       "      <td>[OTICAS FAM, BRASKEM, HAPPY, SALA DE VENDAS SE...</td>\n",
       "      <td>[53796458000165, 42150391003005, 5873166200518...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>kadrangular ebanjeio</td>\n",
       "      <td>KADRANGULAR EBANJEIO</td>\n",
       "      <td>IGREJA DO EVANGELHO QUADRANGULAR</td>\n",
       "      <td>CRUZADA NACIONAL DE EVANGELIZACAO</td>\n",
       "      <td>igreja evangelho quadrangular</td>\n",
       "      <td>cruzada nacional evangelizacao</td>\n",
       "      <td>62955505108952</td>\n",
       "      <td>AL</td>\n",
       "      <td>KASANOVA LTDA</td>\n",
       "      <td>KASANOVA</td>\n",
       "      <td>54045999000114</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[KASANOVA LTDA, MINISTERIO IGREJA VIVA, TECNOL...</td>\n",
       "      <td>[KASANOVA, MINISTERIO IGREJA VIVA, TECBAN, NUT...</td>\n",
       "      <td>[54045999000114, 49232475000100, 5142710202988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60444</th>\n",
       "      <td>pavel</td>\n",
       "      <td>PAVEL</td>\n",
       "      <td>DIMED S/A - DISTRIBUIDORA DE MEDICAMENTOS</td>\n",
       "      <td>PANVEL FARMACIAS</td>\n",
       "      <td>dimed distribuidora medicamentos</td>\n",
       "      <td>panvel farmacias</td>\n",
       "      <td>92665611068995</td>\n",
       "      <td>SC</td>\n",
       "      <td>SCHNEIDER &amp; CIA LTDA</td>\n",
       "      <td>SCHNEIDER &amp; CIA</td>\n",
       "      <td>82646803000182</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[SCHNEIDER &amp; CIA LTDA, BERTAN ADM DE BENS LTDA...</td>\n",
       "      <td>[SCHNEIDER &amp; CIA, BERTAN ADM DE BENS, C.C. CAN...</td>\n",
       "      <td>[82646803000182, 57314495000140, 4930083000012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114369</th>\n",
       "      <td>frisxmann</td>\n",
       "      <td>FRISXMANN</td>\n",
       "      <td>DIAGNOSTICOS DA AMERICA S.A .</td>\n",
       "      <td>FRISCHMANN AISENGART</td>\n",
       "      <td>diagnosticos america</td>\n",
       "      <td>frischmann aisengart</td>\n",
       "      <td>61486650040487</td>\n",
       "      <td>PR</td>\n",
       "      <td>M ROSENMANN JOALHEIROS S/A</td>\n",
       "      <td>M ROSENMANN JOALHEIROS</td>\n",
       "      <td>76560168000547</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[M ROSENMANN JOALHEIROS S/A, M ROSENMANN JOALH...</td>\n",
       "      <td>[M ROSENMANN JOALHEIROS, M ROSENMANN JOALHEIRO...</td>\n",
       "      <td>[76560168000547, 76560168006235, 7656016800011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264852</th>\n",
       "      <td>cooperativa fronteiras</td>\n",
       "      <td>COOPERATIVA FRONTEIRAS</td>\n",
       "      <td>COOPERATIVA DE CREDITO POUPANCA E INVESTIMENTO...</td>\n",
       "      <td>UNIDADE DE ATENDIMENTO DE PRANCHITA-PR</td>\n",
       "      <td>cooperativa credito poupanca investimento fron...</td>\n",
       "      <td>unidade atendimento pranchita pr</td>\n",
       "      <td>82527557001030</td>\n",
       "      <td>PR</td>\n",
       "      <td>COOPERATIVA AGROPECUARIA SAO LOURENCO - CASLO</td>\n",
       "      <td>CASLO</td>\n",
       "      <td>83675918002292</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[COOPERATIVA AGROPECUARIA SAO LOURENCO - CASLO...</td>\n",
       "      <td>[CASLO, ALTO DA XV, NOVA ESPERANCA, PORTAO / M...</td>\n",
       "      <td>[83675918002292, 61012019138683, 6101201906454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52239</th>\n",
       "      <td>sabesp conpanhia</td>\n",
       "      <td>SABESP CONPANHIA</td>\n",
       "      <td>COMPANHIA DE SANEAMENTO BASICO DO ESTADO DE SA...</td>\n",
       "      <td>SABESP</td>\n",
       "      <td>saneamento basico estado sao paulo sabesp</td>\n",
       "      <td>sabesp</td>\n",
       "      <td>43776517058854</td>\n",
       "      <td>SP</td>\n",
       "      <td>ASSOCIACAO SABESP</td>\n",
       "      <td>ASSOC. SABESP - DIR. REG. VALE DO PARAIBA</td>\n",
       "      <td>49750839000306</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[ASSOCIACAO SABESP, ASSOCIACAO SABESP, FANTINA...</td>\n",
       "      <td>[ASSOC. SABESP - DIR. REG. VALE DO PARAIBA, AS...</td>\n",
       "      <td>[49750839000306, 49750839000489, 5514498200018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98022</th>\n",
       "      <td>drogaria</td>\n",
       "      <td>DROGARIA</td>\n",
       "      <td>FARMACIA E DROGARIA NISSEI S.A</td>\n",
       "      <td>DROGARIA NISSEI</td>\n",
       "      <td>farmacia drogaria nissei</td>\n",
       "      <td>drogaria nissei</td>\n",
       "      <td>79430682014344</td>\n",
       "      <td>PR</td>\n",
       "      <td>DROGARIA SAO PAULO S.A.</td>\n",
       "      <td>DROGARIA SAO PAULO</td>\n",
       "      <td>61412110029560</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[DROGARIA SAO PAULO S.A., RAIA DROGASIL S/A, R...</td>\n",
       "      <td>[DROGARIA SAO PAULO, DROGARAIA, DROGARAIA, DRO...</td>\n",
       "      <td>[61412110029560, 61585865205390, 6158586524151...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234917</th>\n",
       "      <td>farmasia nosa senhora</td>\n",
       "      <td>FARMASIA NOSA SENHORA</td>\n",
       "      <td>FARMACIA NOSSA SENHORA DO ROSARIO LTDA - EM RE...</td>\n",
       "      <td>FARMACIA ROSARIO</td>\n",
       "      <td>farmacia nossa senhora rosario recuperacao jud...</td>\n",
       "      <td>farmacia rosario</td>\n",
       "      <td>59603977003323</td>\n",
       "      <td>SP</td>\n",
       "      <td>FARMACIA E DROGARIA NISSEI S.A</td>\n",
       "      <td>FARMACIA E DROGARIA NISSEI LTDA</td>\n",
       "      <td>79430682023505</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[FARMACIA E DROGARIA NISSEI S.A, FARMACIA E DR...</td>\n",
       "      <td>[FARMACIA E DROGARIA NISSEI LTDA, FARMACIA E D...</td>\n",
       "      <td>[79430682023505, 79430682023840, 7943068203461...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user_input  user_input_not_cleaned  \\\n",
       "181538             deus franca             DEUS FRANCA   \n",
       "36661        sao joao faramsia       SAO JOAO FARAMSIA   \n",
       "167507                  bras i             BRAS DE A I   \n",
       "11988     kadrangular ebanjeio    KADRANGULAR EBANJEIO   \n",
       "60444                    pavel                   PAVEL   \n",
       "...                        ...                     ...   \n",
       "114369               frisxmann               FRISXMANN   \n",
       "264852  cooperativa fronteiras  COOPERATIVA FRONTEIRAS   \n",
       "52239         sabesp conpanhia        SABESP CONPANHIA   \n",
       "98022                 drogaria                DROGARIA   \n",
       "234917   farmasia nosa senhora   FARMASIA NOSA SENHORA   \n",
       "\n",
       "                                  razaosocial_not_cleaned  \\\n",
       "181538  IGREJA EVANGELICA ASSEMBLEIA DE DEUS EM FRANCA-SP   \n",
       "36661                 COMERCIO DE MEDICAMENTOS BRAIR LTDA   \n",
       "167507  ASSOCIACAO BRASILEIRA D'A IGREJA DE JESUS CRIS...   \n",
       "11988                    IGREJA DO EVANGELHO QUADRANGULAR   \n",
       "60444           DIMED S/A - DISTRIBUIDORA DE MEDICAMENTOS   \n",
       "...                                                   ...   \n",
       "114369                      DIAGNOSTICOS DA AMERICA S.A .   \n",
       "264852  COOPERATIVA DE CREDITO POUPANCA E INVESTIMENTO...   \n",
       "52239   COMPANHIA DE SANEAMENTO BASICO DO ESTADO DE SA...   \n",
       "98022                      FARMACIA E DROGARIA NISSEI S.A   \n",
       "234917  FARMACIA NOSSA SENHORA DO ROSARIO LTDA - EM RE...   \n",
       "\n",
       "                                nome_fantasia_not_cleaned  \\\n",
       "181538                                 ASSEMBLEIA DE DEUS   \n",
       "36661                                  SAO JOAO FARMACIAS   \n",
       "167507  ASSOC BRAS DE A I DE JESUS CRISTO DOS SANTOS D...   \n",
       "11988                   CRUZADA NACIONAL DE EVANGELIZACAO   \n",
       "60444                                    PANVEL FARMACIAS   \n",
       "...                                                   ...   \n",
       "114369                               FRISCHMANN AISENGART   \n",
       "264852             UNIDADE DE ATENDIMENTO DE PRANCHITA-PR   \n",
       "52239                                              SABESP   \n",
       "98022                                     DROGARIA NISSEI   \n",
       "234917                                   FARMACIA ROSARIO   \n",
       "\n",
       "                                              razaosocial  \\\n",
       "181538        igreja evangelica assembleia deus franca sp   \n",
       "36661                                  medicamentos brair   \n",
       "167507  associacao brasileira d a igreja jesus cristo ...   \n",
       "11988                       igreja evangelho quadrangular   \n",
       "60444                    dimed distribuidora medicamentos   \n",
       "...                                                   ...   \n",
       "114369                               diagnosticos america   \n",
       "264852  cooperativa credito poupanca investimento fron...   \n",
       "52239           saneamento basico estado sao paulo sabesp   \n",
       "98022                            farmacia drogaria nissei   \n",
       "234917  farmacia nossa senhora rosario recuperacao jud...   \n",
       "\n",
       "                                  nome_fantasia            cnpj  uf  \\\n",
       "181538                          assembleia deus  47041223002376  SP   \n",
       "36661                        sao joao farmacias  88212113030351  RS   \n",
       "167507  assoc bras i jesus cristo santos u dias  61012019060986  BA   \n",
       "11988            cruzada nacional evangelizacao  62955505108952  AL   \n",
       "60444                          panvel farmacias  92665611068995  SC   \n",
       "...                                         ...             ...  ..   \n",
       "114369                     frischmann aisengart  61486650040487  PR   \n",
       "264852         unidade atendimento pranchita pr  82527557001030  PR   \n",
       "52239                                    sabesp  43776517058854  SP   \n",
       "98022                           drogaria nissei  79430682014344  PR   \n",
       "234917                         farmacia rosario  59603977003323  SP   \n",
       "\n",
       "                              top_1_razaosocial_retrieved  \\\n",
       "181538                     NOVA FRANCA PARTICIPACOES LTDA   \n",
       "36661   ASSOCIACAO BRASILEIRA D'A IGREJA DE JESUS CRIS...   \n",
       "167507                                    OTICAS FAM LTDA   \n",
       "11988                                       KASANOVA LTDA   \n",
       "60444                                SCHNEIDER & CIA LTDA   \n",
       "...                                                   ...   \n",
       "114369                         M ROSENMANN JOALHEIROS S/A   \n",
       "264852      COOPERATIVA AGROPECUARIA SAO LOURENCO - CASLO   \n",
       "52239                                   ASSOCIACAO SABESP   \n",
       "98022                             DROGARIA SAO PAULO S.A.   \n",
       "234917                     FARMACIA E DROGARIA NISSEI S.A   \n",
       "\n",
       "                     top_1_nomefantasia_retrieved top_1_cnpj_retrieved  \\\n",
       "181538                    NOVA FRANCA IMOBILIARIA       47998745000155   \n",
       "36661                      SAO FRANCISCO DE PAULA       61012019158366   \n",
       "167507                                 OTICAS FAM       53796458000165   \n",
       "11988                                    KASANOVA       54045999000114   \n",
       "60444                             SCHNEIDER & CIA       82646803000182   \n",
       "...                                           ...                  ...   \n",
       "114369                     M ROSENMANN JOALHEIROS       76560168000547   \n",
       "264852                                      CASLO       83675918002292   \n",
       "52239   ASSOC. SABESP - DIR. REG. VALE DO PARAIBA       49750839000306   \n",
       "98022                          DROGARIA SAO PAULO       61412110029560   \n",
       "234917            FARMACIA E DROGARIA NISSEI LTDA       79430682023505   \n",
       "\n",
       "        top_1_razaosocial_pred  top_1_nomefantasia_pred  top_1_cnpj_pred  \\\n",
       "181538                   False                    False            False   \n",
       "36661                    False                    False            False   \n",
       "167507                   False                    False            False   \n",
       "11988                    False                    False            False   \n",
       "60444                    False                    False            False   \n",
       "...                        ...                      ...              ...   \n",
       "114369                   False                    False            False   \n",
       "264852                   False                    False            False   \n",
       "52239                    False                    False            False   \n",
       "98022                    False                    False            False   \n",
       "234917                   False                    False            False   \n",
       "\n",
       "        top_5_razaosocial_pred  top_5_nomefantasia_pred  top_5_cnpj_pred  \\\n",
       "181538                   False                    False            False   \n",
       "36661                    False                    False            False   \n",
       "167507                   False                    False            False   \n",
       "11988                    False                    False            False   \n",
       "60444                    False                    False            False   \n",
       "...                        ...                      ...              ...   \n",
       "114369                   False                    False            False   \n",
       "264852                   False                    False            False   \n",
       "52239                    False                    False            False   \n",
       "98022                    False                    False            False   \n",
       "234917                   False                    False            False   \n",
       "\n",
       "                                   top_k_razaosocial_pred  \\\n",
       "181538  [NOVA FRANCA PARTICIPACOES LTDA, CONFECCOES AL...   \n",
       "36661   [ASSOCIACAO BRASILEIRA D'A IGREJA DE JESUS CRI...   \n",
       "167507  [OTICAS FAM LTDA, BRASKEM S.A, RI HAPPY BRINQU...   \n",
       "11988   [KASANOVA LTDA, MINISTERIO IGREJA VIVA, TECNOL...   \n",
       "60444   [SCHNEIDER & CIA LTDA, BERTAN ADM DE BENS LTDA...   \n",
       "...                                                   ...   \n",
       "114369  [M ROSENMANN JOALHEIROS S/A, M ROSENMANN JOALH...   \n",
       "264852  [COOPERATIVA AGROPECUARIA SAO LOURENCO - CASLO...   \n",
       "52239   [ASSOCIACAO SABESP, ASSOCIACAO SABESP, FANTINA...   \n",
       "98022   [DROGARIA SAO PAULO S.A., RAIA DROGASIL S/A, R...   \n",
       "234917  [FARMACIA E DROGARIA NISSEI S.A, FARMACIA E DR...   \n",
       "\n",
       "                                  top_k_nomefantasia_pred  \\\n",
       "181538  [NOVA FRANCA IMOBILIARIA, CONFECCOES ALVARO, E...   \n",
       "36661   [SAO FRANCISCO DE PAULA, SUPERMERCADO CARANGOL...   \n",
       "167507  [OTICAS FAM, BRASKEM, HAPPY, SALA DE VENDAS SE...   \n",
       "11988   [KASANOVA, MINISTERIO IGREJA VIVA, TECBAN, NUT...   \n",
       "60444   [SCHNEIDER & CIA, BERTAN ADM DE BENS, C.C. CAN...   \n",
       "...                                                   ...   \n",
       "114369  [M ROSENMANN JOALHEIROS, M ROSENMANN JOALHEIRO...   \n",
       "264852  [CASLO, ALTO DA XV, NOVA ESPERANCA, PORTAO / M...   \n",
       "52239   [ASSOC. SABESP - DIR. REG. VALE DO PARAIBA, AS...   \n",
       "98022   [DROGARIA SAO PAULO, DROGARAIA, DROGARAIA, DRO...   \n",
       "234917  [FARMACIA E DROGARIA NISSEI LTDA, FARMACIA E D...   \n",
       "\n",
       "                                          top_k_cnpj_pred  \n",
       "181538  [47998745000155, 43306715000180, 6070119031004...  \n",
       "36661   [61012019158366, 94739992000117, 6101201910940...  \n",
       "167507  [53796458000165, 42150391003005, 5873166200518...  \n",
       "11988   [54045999000114, 49232475000100, 5142710202988...  \n",
       "60444   [82646803000182, 57314495000140, 4930083000012...  \n",
       "...                                                   ...  \n",
       "114369  [76560168000547, 76560168006235, 7656016800011...  \n",
       "264852  [83675918002292, 61012019138683, 6101201906454...  \n",
       "52239   [49750839000306, 49750839000489, 5514498200018...  \n",
       "98022   [61412110029560, 61585865205390, 6158586524151...  \n",
       "234917  [79430682023505, 79430682023840, 7943068203461...  \n",
       "\n",
       "[233 rows x 20 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df['top_5_razaosocial_pred'] == False]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
